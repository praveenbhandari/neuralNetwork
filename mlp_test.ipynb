{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=[1,2,3,4,5]\n",
    "weight=[0.1,2,10,0.1,0.5]\n",
    "bias = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1-np.exp(x))\n",
    "    \n",
    "def sum_input_to_hiddedn():\n",
    "    sum=0\n",
    "    for i in range(len(input_data)):\n",
    "        sum += input_data[i]*weight[i]\n",
    "    return sum+bias\n",
    "\n",
    "\n",
    "def cost(input):\n",
    "    input=input\n",
    "    output=sigmoid(sum_input_to_hiddedn())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-3.1391327920480296e-17)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer=5\n",
    "hidden_layer=3\n",
    "output_layer=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron():\n",
    "    def __init__(self,bias=1):\n",
    "        self.bias=bias\n",
    "        self.weight=[]\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1-np.exp(x))\n",
    "    \n",
    "    def sum_input_to_hiddedn(self):\n",
    "        sum=0\n",
    "        for i in range(len(self.input)):\n",
    "            sum += self.input[i]*self.weight[i]\n",
    "            print(sum)\n",
    "        return sum+self.bias\n",
    "    \n",
    "\n",
    "    def cost(self,input):\n",
    "        self.input=input\n",
    "        self.output=self.sigmoid(self.sum_input_to_hiddedn())\n",
    "        return self.output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.neuron at 0x10e335760>,\n",
       " <__main__.neuron at 0x10e329100>,\n",
       " <__main__.neuron at 0x10e3366c0>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# req - hidden layers\n",
    "network=[]\n",
    "for i in range(hidden_layer):\n",
    "    network.append(neuron())\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network[2].cost(input_data,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in network:\n",
    "#     print(i.cost(input_data,weight))\n",
    "# # network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in network:\n",
    "    # print(i.input,i.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "    def __init__(self,hidden_layer):\n",
    "        self.network=[]\n",
    "        for i in range(hidden_layer):\n",
    "            self.network.append(neuron())\n",
    "\n",
    "    def forward(self,input):\n",
    "        outputs=[]\n",
    "        for i in self.network:\n",
    "            outputs.append(i.cost(input))\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=[1,2,3,4,5]\n",
    "weight=[0.1,2,10,0.1,0.5]\n",
    "bias = 1\n",
    "hidden_l_network=network(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.neuron at 0x10e336ed0>,\n",
       " <__main__.neuron at 0x10e337cb0>,\n",
       " <__main__.neuron at 0x10e335af0>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_l_network.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hidden_l_network.network)):\n",
    "    # print(hidden_l_network.network[i].weight)\n",
    "    for j in range(len(input_data)):\n",
    "        hidden_l_network.network[i].weight.append(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8139919160307355, 0.4007176124160069, 0.4374317262788818, 0.2232735735545146, 0.9138897007121772, 0.4044905587671861]\n",
      "[0.42543353996520383, 0.402582477270949, 0.24355663495316715, 0.09345137758554656, 0.7130496540233595, 0.8130382049543704]\n",
      "[0.2548631394498, 0.7797079319457844, 0.19928905261201968, 0.1566119980050079, 0.3878079470821586, 0.7879064367817528]\n"
     ]
    }
   ],
   "source": [
    "print(hidden_l_network.network[0].weight)\n",
    "print(hidden_l_network.network[1].weight)\n",
    "print(hidden_l_network.network[2].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_l_network=network(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(output_l_network.network)):\n",
    "    # print(hidden_l_network.network[i].weight)\n",
    "    for j in range(len(input_data)):\n",
    "        output_l_network.network[i].weight.append(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2768969433526579, 0.2286451908017909, 0.48217887856669783, 0.4718352597341168, 0.9914376431006002]\n",
      "[0.47893350416817615, 0.418192899824686, 0.3682396263116494, 0.9993480057023378, 0.4410274141053805]\n",
      "[0.876124096770342, 0.09416475883428588, 0.2052788543285966, 0.4221434797800523, 0.4819842108616965]\n"
     ]
    }
   ],
   "source": [
    "print(output_l_network.network[0].weight)\n",
    "print(output_l_network.network[1].weight)\n",
    "print(output_l_network.network[2].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_network():\n",
    "    def __init__(self,n_input_layer,n_hidden_layer,n_output_layer):\n",
    "        self.hidden_l_network=network(n_hidden_layer)\n",
    "        self.output_l_network=network(n_output_layer)\n",
    "        self.n_input_layer=n_input_layer\n",
    "        self.hidden_weight_layer=self.add_weights_to_hidden()\n",
    "        self.output_weight_layer=self.add_weights_to_output()\n",
    "\n",
    "\n",
    "    def add_weights_to_hidden(self):\n",
    "        for i in range(len(self.hidden_l_network.network)):\n",
    "            # print(hidden_l_network.network[i].weight)\n",
    "            for j in range((self.n_input_layer)):\n",
    "                self.hidden_l_network.network[i].weight.append(random.random())\n",
    "\n",
    "    def add_weights_to_output(self):\n",
    "        for i in range(len(self.output_l_network.network)):\n",
    "            # print(hidden_l_network.network[i].weight)\n",
    "            for j in range((self.n_input_layer)):\n",
    "                self.output_l_network.network[i].weight.append(random.random())\n",
    "\n",
    "    def forward_hidden_op(self,input_data):\n",
    "        self.hidden_l_cost=self.hidden_l_network.forward(input_data)\n",
    "        return self.output_l_network.forward(hidden_l_network)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ass=all_network(5,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1799231276005897\n",
      "1.2916252457118116\n",
      "2.9867517886396087\n",
      "6.42020574631419\n",
      "11.333522569560623\n",
      "0.8383387126610957\n",
      "2.2285709912903533\n",
      "4.326831627129644\n",
      "5.448736497866511\n",
      "8.171466471286266\n",
      "0.13128276666423822\n",
      "1.4059899375650755\n",
      "3.9894535190891753\n",
      "7.976248774831776\n",
      "11.89511812743319\n",
      "0.7842991227464586\n",
      "2.2060204494060986\n",
      "3.4032327724981823\n",
      "5.169747818079063\n",
      "8.52245917527577\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'network' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_hidden_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[122], line 24\u001b[0m, in \u001b[0;36mall_network.forward_hidden_op\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_hidden_op\u001b[39m(\u001b[38;5;28mself\u001b[39m,input_data):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_l_cost\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_l_network\u001b[38;5;241m.\u001b[39mforward(input_data)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_l_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_l_network\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[121], line 10\u001b[0m, in \u001b[0;36mnetwork.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      8\u001b[0m outputs\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork:\n\u001b[0;32m---> 10\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[0;32mIn[120], line 19\u001b[0m, in \u001b[0;36mneuron.cost\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum_input_to_hiddedn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\n",
      "Cell \u001b[0;32mIn[120], line 11\u001b[0m, in \u001b[0;36mneuron.sum_input_to_hiddedn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum_input_to_hiddedn\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28msum\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput[i]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[i]\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'network' has no len()"
     ]
    }
   ],
   "source": [
    "ass.forward_hidden_op(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward output: [0.7513650695523157, 0.7729284653214625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, bias):\n",
    "        self.bias = bias\n",
    "        self.weight = []\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sum_input_to_hidden(self):\n",
    "        total = 0\n",
    "        for i in range(len(self.input)):\n",
    "            total += self.input[i] * self.weight[i]\n",
    "        return total + self.bias\n",
    "\n",
    "    def cost(self, input):\n",
    "        self.input = input\n",
    "        self.output = self.sigmoid(self.sum_input_to_hidden())\n",
    "        return self.output\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, hidden_layer, bias):\n",
    "        self.network = []\n",
    "        self.bias = bias if bias else random.random()\n",
    "        for i in range(hidden_layer):\n",
    "            self.network.append(Neuron(self.bias))\n",
    "\n",
    "    def forward(self, input):\n",
    "        outputs = []\n",
    "        for neuron in self.network:\n",
    "            outputs.append(neuron.cost(input))\n",
    "        return outputs\n",
    "\n",
    "class AllNetwork:\n",
    "    def __init__(self, n_input_layer, n_hidden_layer, n_output_layer, hidden_weights, output_weights, hidden_bias, output_bias):\n",
    "        self.hidden_l_network = Network(n_hidden_layer, hidden_bias)\n",
    "        self.output_l_network = Network(n_output_layer, output_bias)\n",
    "        self.n_input_layer = n_input_layer\n",
    "        self.hidden_weight_layer = self.add_weights_to_hidden(hidden_weights)\n",
    "        self.output_weight_layer = self.add_weights_to_output(output_weights)\n",
    "\n",
    "    def add_weights_to_hidden(self, hidden_weights):\n",
    "        count = 0\n",
    "        for neuron in self.hidden_l_network.network:\n",
    "            for _ in range(self.n_input_layer):\n",
    "                neuron.weight.append(hidden_weights[count])\n",
    "                count += 1\n",
    "\n",
    "    def add_weights_to_output(self, output_weights):\n",
    "        count = 0\n",
    "        for neuron in self.output_l_network.network:\n",
    "            for _ in range(len(self.hidden_l_network.network)):  # Use hidden layer size here\n",
    "                neuron.weight.append(output_weights[count])\n",
    "                count += 1\n",
    "\n",
    "    def forward_hidden_op(self, input_data):\n",
    "        hidden_outputs = self.hidden_l_network.forward(input_data)\n",
    "        return self.output_l_network.forward(hidden_outputs)\n",
    "\n",
    "# Testing the corrected network\n",
    "n = AllNetwork(2, 2, 2, [0.15, 0.2, 0.25, 0.3], [0.4, 0.45, 0.5, 0.55], 0.35, 0.6)\n",
    "output = n.forward_hidden_op([0.05, 0.1])\n",
    "print(\"Feedforward output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Backporpogation test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron():\n",
    "    def __init__(self,bias):\n",
    "        self.bias=bias\n",
    "        self.weight=[]\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sum_input_to_hiddedn(self):\n",
    "        sum=0\n",
    "        for i in range(len(self.input)):\n",
    "            sum += self.input[i]*self.weight[i]\n",
    "            # print(sum)\n",
    "        return sum+self.bias\n",
    "    \n",
    "\n",
    "    def cost(self,input):\n",
    "        self.input=input\n",
    "        self.output=self.sigmoid(self.sum_input_to_hiddedn())\n",
    "        return self.output\n",
    "class network():\n",
    "    def __init__(self,hidden_layer,bias):\n",
    "        self.network=[]\n",
    "        self.bias = bias if bias else random.random()\n",
    "        for _ in range(hidden_layer):\n",
    "            self.network.append(neuron(self.bias))\n",
    "\n",
    "    def forward(self,input):\n",
    "        outputs=[]\n",
    "        for i in self.network:\n",
    "            outputs.append(i.cost(input))\n",
    "        return outputs\n",
    "    \n",
    "class all_network():\n",
    "    def __init__(self,n_input_layer,n_hidden_layer,n_output_layer,hidden_weights,output_weights,hidden_bias,output_bias):\n",
    "        self.hidden_l_network=network(n_hidden_layer,hidden_bias)\n",
    "        self.output_l_network=network(n_output_layer,output_bias)\n",
    "        self.n_input_layer=n_input_layer\n",
    "        # self.hidden_weight_layer=self.add_weights_to_hidden(hidden_weights)\n",
    "        # self.output_weight_layer=self.add_weights_to_output(output_weights)\n",
    "        self.add_weights(self.hidden_l_network,hidden_weights,n_input_layer)\n",
    "        self.add_weights(self.output_l_network,output_weights,n_hidden_layer)\n",
    "\n",
    "\n",
    "    def add_weights(self, layer, weights, num_inputs):\n",
    "        count = 0\n",
    "        for neuron in layer.network:\n",
    "            for _ in range(num_inputs):\n",
    "                neuron.weight.append(weights[count])\n",
    "                count += 1\n",
    "\n",
    "    # def add_weights_to_output(self,output_weights):\n",
    "    #     count=0\n",
    "    #     for i in range(len(self.output_l_network.network)):\n",
    "    #         # print(hidden_l_network.network[i].weight)\n",
    "    #         for j in range((self.n_input_layer)):\n",
    "    #             self.output_l_network.network[i].weight.append(output_weights[count])\n",
    "    #             count+=1\n",
    "\n",
    "    def forward_hidden_op(self,input_data):\n",
    "        self.hidden_l_cost=self.hidden_l_network.forward(input_data)\n",
    "        print(\"Hidden layer outputs:\", self.hidden_l_cost)\n",
    "        self.output_l_cost=self.output_l_network.forward(self.hidden_l_cost)\n",
    "        print(\"Output layer outputs:\", self.output_l_cost)  # Print output layer outputs\n",
    "\n",
    "        return self.output_l_cost\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
