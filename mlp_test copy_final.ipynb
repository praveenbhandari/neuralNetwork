{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron():\n",
    "    def __init__(self,bias):\n",
    "        self.bias=bias\n",
    "        self.weights=[]\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sum_input_to_hiddedn(self):\n",
    "        sum=0\n",
    "        for i in range(len(self.input)):\n",
    "            sum += self.input[i]*self.weights[i]\n",
    "            # print(sum)\n",
    "        return sum+self.bias\n",
    "    \n",
    "    \n",
    "\n",
    "    def cost(self,input):\n",
    "        self.input=input\n",
    "        self.output=self.sigmoid(self.sum_input_to_hiddedn())\n",
    "        return self.output\n",
    "    \n",
    "    def cal_error(self,target_op):\n",
    "        return 0.5*np.square(target_op-self.output)\n",
    "    \n",
    "    def error_wrt_output(self, targer_op):\n",
    "        return -(targer_op-self.output)\n",
    "\n",
    "\n",
    "    def error_wrt_input(self):\n",
    "        return self.output*(1-self.output)\n",
    "\n",
    "    def total_error(self,targer_op):\n",
    "        return self.error_wrt_input()*self.error_wrt_output(targer_op)\n",
    "    \n",
    "\n",
    "    # def error_wrt_weight(self,index):\n",
    "    #     return self.input[index]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "    def __init__(self,hidden_layer,bias):\n",
    "        self.network=[]\n",
    "        self.bias = bias if bias is not None else random.random()\n",
    "        for _ in range(hidden_layer):\n",
    "            self.network.append(neuron(self.bias))\n",
    "\n",
    "    def forward(self,input):\n",
    "        outputs=[]\n",
    "        for i in self.network:\n",
    "            outputs.append(i.cost(input))\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "    # def backPropogation(self,):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_network():\n",
    "    def __init__(self,n_input_layer,n_hidden_layer,n_output_layer,hidden_weights,output_weights,hidden_bias,output_bias):\n",
    "        self.hidden_l_network=network(n_hidden_layer,hidden_bias)\n",
    "        self.output_l_network=network(n_output_layer,output_bias)\n",
    "        self.n_input_layer=n_input_layer\n",
    "        # self.hidden_weight_layer=self.add_weights_to_hidden(hidden_weights)\n",
    "        # self.output_weight_layer=self.add_weights_to_output(output_weights)\n",
    "        self.add_weights(self.hidden_l_network,hidden_weights,n_input_layer)\n",
    "        self.add_weights(self.output_l_network,output_weights,n_hidden_layer)\n",
    "\n",
    "\n",
    "    def add_weights(self, layer, weight, num_inputs):\n",
    "        count = 0\n",
    "        for neuron in layer.network:\n",
    "            for _ in range(num_inputs):\n",
    "                neuron.weights.append(weight[count])\n",
    "                count += 1\n",
    "\n",
    "    # def add_weights_to_output(self,output_weights):\n",
    "    #     count=0\n",
    "    #     for i in range(len(self.output_l_network.network)):\n",
    "    #         # print(hidden_l_network.network[i].weight)\n",
    "    #         for j in range((self.n_input_layer)):\n",
    "    #             self.output_l_network.network[i].weight.append(output_weights[count])\n",
    "    #             count+=1\n",
    "\n",
    "    def forward_hidden_op(self,input_data):\n",
    "        hidden_op=self.hidden_l_network.forward(input_data)\n",
    "        # self.hidden_l_cost=self.hidden_l_network.forward(input_data)\n",
    "        # print(\"Hidden layer outputs:\", self.hidden_l_cost)\n",
    "        # self.output_l_cost=self.output_l_network.forward(self.hidden_l_cost)\n",
    "        # print(\"Output layer outputs:\", self.output_l_cost)  # Print output layer outputs\n",
    "\n",
    "        return self.output_l_network.forward(hidden_op)\n",
    "    \n",
    "    def backPropogation(self, input_data, target_op,learning_rate=0.5):\n",
    "        # Output layer deltas\n",
    "        # self.forward_hidden_op(target_inp)\n",
    "        hidden_output = self.hidden_l_network.forward(input_data)\n",
    "        final_output = self.output_l_network.forward(hidden_output)\n",
    "\n",
    "        # output_deltas = [0] * len(self.output_l_network.network)\n",
    "        # for i in range(len(self.output_l_network.network)):\n",
    "        #     output_deltas[i] = self.output_l_network.network[i].cal_error(target_op[i])\n",
    "\n",
    "        output_deltas = []\n",
    "        for i in range(len(target_op)):\n",
    "            error_wrt_input = self.output_l_network.network[i].error_wrt_input()\n",
    "            output_deltas.append((target_op[i] - final_output[i]) * error_wrt_input)\n",
    "\n",
    "        # Hidden layer deltas\n",
    "        hidden_deltas = []\n",
    "        for i in range(len(self.hidden_l_network.network)):\n",
    "            # Calculate the weighted sum of output deltas for the current hidden layer neuron\n",
    "            weighted_sum = 0\n",
    "            for j in range(len(self.output_l_network.network)):\n",
    "                weighted_sum += output_deltas[j] * self.output_l_network.network[j].weights[i]\n",
    "            \n",
    "            # Multiply the weighted sum by the error with respect to the input\n",
    "            hidden_deltas.append(weighted_sum * self.hidden_l_network.network[i].error_wrt_input())\n",
    "\n",
    "        # Update output weights and biases\n",
    "        for i, neuron in enumerate(self.output_l_network.network):\n",
    "            for j in range(len(neuron.weights)):\n",
    "                neuron.weights[j] += learning_rate * output_deltas[i] * hidden_output[j]\n",
    "            neuron.bias += learning_rate * output_deltas[i]\n",
    "  \n",
    "\n",
    "        # Update hidden weights and biases\n",
    "        for i, neuron in enumerate(self.hidden_l_network.network):\n",
    "            for j in range(len(neuron.weights)):\n",
    "                neuron.weights[j] += learning_rate * hidden_deltas[i] * input_data[j]\n",
    "            neuron.bias += learning_rate * hidden_deltas[i]\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_total_error(self, dataset):\n",
    "        total_error = 0\n",
    "        for input_data, target_op in dataset:\n",
    "            outputs = self.forward_hidden_op(input_data)\n",
    "            total_error += sum(0.5 * (target_op[i] - outputs[i]) ** 2 for i in range(len(target_op)))\n",
    "        return total_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        # // TODO: hidden layer delta calculations using chain rule\n",
    "        # for i in range(len(self.hidden_l_network.network)):\n",
    "        #     d=0\n",
    "        #     for j in range(len(self.output_l_network.network)):\n",
    "        #         # error_at_hidden_layer[i] = self.hidden_l_network[i].total_error(target_inp[i])\n",
    "        #         d=error_at_op[i]*self.output_l_network.network[j].weights[i]\n",
    "        #     error_at_hidden_layer[i] = d*self.hidden_l_network.network[i].error_wrt_input()\n",
    "\n",
    "        \n",
    "        # for i in range(len(self.output_l_network.network)):\n",
    "        #     for j in range(len(self.hidden_l_network.network[i].weights)):\n",
    "        #         error_wrt_weight=error_at_op * self.output_l_network.network[i].error_wrt_weight(j)\n",
    "        #         self.hidden_l_network.network[i].weight[j]-= 0.5*error_wrt_weight\n",
    "\n",
    "\n",
    "\n",
    "        # for i in range(len(self.hidden_l_network.network)):\n",
    "        #     for j in range(len(self.hidden_l_network.network[i].weights)):\n",
    "        #         error_wrt_weight=error_at_hidden_layer * self.hidden_l_network.network[i].error_wrt_weight(j)\n",
    "        #         self.output_l_network.network[i].weight[j]-= 0.5*error_wrt_weight\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.280471447\n",
      "1 0.261907623\n",
      "2 0.242935433\n",
      "3 0.223873213\n",
      "4 0.205075318\n",
      "5 0.186895748\n",
      "6 0.169649683\n",
      "7 0.153582241\n",
      "8 0.138851411\n",
      "9 0.125527038\n",
      "10 0.113602735\n",
      "11 0.103014893\n",
      "12 0.093663058\n",
      "13 0.085427754\n",
      "14 0.078183997\n",
      "15 0.07181033\n",
      "16 0.066194128\n",
      "17 0.061234149\n",
      "18 0.056841263\n",
      "19 0.052938092\n",
      "20 0.04945807\n",
      "21 0.046344249\n",
      "22 0.043548059\n",
      "23 0.041028127\n",
      "24 0.038749202\n",
      "25 0.036681218\n",
      "26 0.034798481\n",
      "27 0.033078983\n",
      "28 0.031503823\n",
      "29 0.03005672\n",
      "30 0.028723603\n",
      "31 0.027492278\n",
      "32 0.026352138\n",
      "33 0.025293932\n",
      "34 0.02430956\n",
      "35 0.023391912\n",
      "36 0.022534727\n",
      "37 0.021732474\n",
      "38 0.02098025\n",
      "39 0.020273704\n",
      "40 0.019608955\n",
      "41 0.018982539\n",
      "42 0.018391352\n",
      "43 0.017832608\n",
      "44 0.017303799\n",
      "45 0.016802663\n",
      "46 0.016327154\n",
      "47 0.01587542\n",
      "48 0.015445776\n",
      "49 0.015036693\n",
      "50 0.014646775\n",
      "51 0.014274747\n",
      "52 0.013919441\n",
      "53 0.013579791\n",
      "54 0.013254813\n",
      "55 0.012943606\n",
      "56 0.012645338\n",
      "57 0.012359242\n",
      "58 0.012084609\n",
      "59 0.011820785\n",
      "60 0.011567162\n",
      "61 0.011323176\n",
      "62 0.011088305\n",
      "63 0.010862061\n",
      "64 0.010643992\n",
      "65 0.010433676\n",
      "66 0.010230717\n",
      "67 0.010034748\n",
      "68 0.009845424\n",
      "69 0.009662423\n",
      "70 0.009485442\n",
      "71 0.009314198\n",
      "72 0.009148424\n",
      "73 0.00898787\n",
      "74 0.008832301\n",
      "75 0.008681494\n",
      "76 0.008535241\n",
      "77 0.008393345\n",
      "78 0.008255619\n",
      "79 0.008121888\n",
      "80 0.007991985\n",
      "81 0.007865754\n",
      "82 0.007743046\n",
      "83 0.00762372\n",
      "84 0.007507641\n",
      "85 0.007394684\n",
      "86 0.007284727\n",
      "87 0.007177657\n",
      "88 0.007073365\n",
      "89 0.006971747\n",
      "90 0.006872705\n",
      "91 0.006776145\n",
      "92 0.006681978\n",
      "93 0.006590118\n",
      "94 0.006500486\n",
      "95 0.006413003\n",
      "96 0.006327595\n",
      "97 0.006244191\n",
      "98 0.006162725\n",
      "99 0.006083131\n"
     ]
    }
   ],
   "source": [
    "nn = all_network(2, 2, 2, hidden_weights=[0.15, 0.2, 0.25, 0.3], hidden_bias=0.35, output_weights=[0.4, 0.45, 0.5, 0.55], output_bias=0.6)\n",
    "\n",
    "# dataset = [([0.05, 0.1], [0.01, 0.99])]\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     nn.backPropogation([0.05, 0.1], [0.01, 0.99])\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f\"Epoch {epoch}: Error = {nn.calculate_total_error(dataset)}\")\n",
    "\n",
    "for i in range(100):\n",
    "    nn.backPropogation([0.05, 0.1], [0.01, 0.99])\n",
    "    print(i, round(nn.calculate_total_error([[[0.05, 0.1], [0.01, 0.99]]]), 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer outputs: [np.float64(0.5932699921071872), np.float64(0.596884378259767)]\n",
      "Output layer outputs: [np.float64(0.7513650695523157), np.float64(0.7729284653214625)]\n"
     ]
    }
   ],
   "source": [
    "n=all_network(2,2,2,[0.15, 0.2, 0.25, 0.3],[0.4, 0.45, 0.5, 0.55],0.35,0.6)\n",
    "output=n.forward_hidden_op([0.05, 0.1])\n",
    "output\n",
    "n.backPropogation([0.05, 0.1], [0.01, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackPropogation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 42\u001b[0m, in \u001b[0;36mall_network.backPropogation\u001b[0;34m(self, target_inp, target_op)\u001b[0m\n\u001b[1;32m     40\u001b[0m error_at_hidden_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_l_network\u001b[38;5;241m.\u001b[39mnetwork)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# print(error_at_hidden_layer,error_at_op)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror_at_op\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(error_at_op[i])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[0]*3\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=all_network(2,5,2,[0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6],[0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85],0.35,0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer outputs: [np.float64(0.5932699921071872), np.float64(0.596884378259767), np.float64(0.6004882745269664), np.float64(0.6040813228693781), np.float64(0.6076631698328917)]\n",
      "Output layer outputs: [np.float64(0.8911937165747111), np.float64(0.945503933223316)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8911937165747111), np.float64(0.945503933223316)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=n.forward_hidden_op([0.05, 0.1])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2\n"
     ]
    }
   ],
   "source": [
    "n.backPropogation([0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6],[0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
