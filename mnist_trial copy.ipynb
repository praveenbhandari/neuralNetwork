{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14e911790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa3UlEQVR4nO3df3BU9b3/8dcmJAtosmkIyWZLwIACrUj8lkKai1IsGUI6l+HX7fVX54Lj4EiDt0CtTjoKop1JxRnr6E3xj6tQZ0SUGYEro8yFYMLYBiwIXy7faobkm0q4kKDcm2wIECL53D+4bruSiCfs5p0Nz8fMmSG755Pz9rjDk8NuDj7nnBMAAP0syXoAAMD1iQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATQ6wH+Kru7m6dPHlSaWlp8vl81uMAADxyzqm9vV2hUEhJSb1f5wy4AJ08eVJ5eXnWYwAArlFTU5NGjRrV6/MDLkBpaWmSpDv0Yw1RivE0AACvvlCXPtC7kd/PexO3AFVWVuq5555Tc3OzCgoK9NJLL2natGlXXfflX7sNUYqG+AgQACSc/73D6NXeRonLhxDefPNNrVq1SmvWrNFHH32kgoIClZSU6PTp0/E4HAAgAcUlQM8//7yWLl2qBx54QN/97nf18ssva/jw4Xr11VfjcTgAQAKKeYAuXryogwcPqri4+K8HSUpScXGxamtrr9i/s7NT4XA4agMADH4xD9Dnn3+uS5cuKScnJ+rxnJwcNTc3X7F/RUWFAoFAZOMTcABwfTD/QdTy8nK1tbVFtqamJuuRAAD9IOafgsvKylJycrJaWlqiHm9paVEwGLxif7/fL7/fH+sxAAADXMyvgFJTUzVlyhRVVVVFHuvu7lZVVZWKiopifTgAQIKKy88BrVq1SosXL9b3v/99TZs2TS+88II6Ojr0wAMPxONwAIAEFJcA3X333frss8+0evVqNTc36/bbb9fOnTuv+GACAOD65XPOOesh/lY4HFYgENBMzeNOCACQgL5wXarWdrW1tSk9Pb3X/cw/BQcAuD4RIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJoZYDwAAXnT8Q6HnNc+uW9+nYz3zj//keY07cLRPx7oecQUEADBBgAAAJmIeoKeeeko+ny9qmzhxYqwPAwBIcHF5D+jWW2/V7t27/3qQIbzVBACIFpcyDBkyRMFgMB7fGgAwSMTlPaBjx44pFApp7Nixuv/++3X8+PFe9+3s7FQ4HI7aAACDX8wDVFhYqI0bN2rnzp1av369Ghsbdeedd6q9vb3H/SsqKhQIBCJbXl5erEcCAAxAMQ9QaWmpfvKTn2jy5MkqKSnRu+++q9bWVr311ls97l9eXq62trbI1tTUFOuRAAADUNw/HZCRkaHx48ervr6+x+f9fr/8fn+8xwAADDBx/zmgs2fPqqGhQbm5ufE+FAAggcQ8QI8++qhqamr0l7/8RX/84x+1YMECJScn69577431oQAACSzmfwV34sQJ3XvvvTpz5oxGjhypO+64Q/v27dPIkSNjfSgAQAKLeYA2b94c6285KJyfN837mhHJntdkvlrreQ2QSE5/3/tf3Dzzl7lxmATXinvBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm4v4P0uGykzO8t374uFbvB3rV+xLATJL3G+660ec9r5mV/YnnNZJU5fu7Pq3DN8MVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwN+x+svbvt3he8+zHs+MwCTBwJI8b43nNJz/0fsv32z/8qec1khT603/0aR2+Ga6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3Iy0n6T4vrAeARhwhvzruX45zvmG9H45DrzhCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSPug+47bPa+5c+gHsR8ESHA33XCmX46Tt/tSvxwH3nAFBAAwQYAAACY8B2jv3r2aO3euQqGQfD6ftm3bFvW8c06rV69Wbm6uhg0bpuLiYh07dixW8wIABgnPAero6FBBQYEqKyt7fH7dunV68cUX9fLLL2v//v264YYbVFJSogsXLlzzsACAwcPzhxBKS0tVWlra43POOb3wwgt64oknNG/ePEnSa6+9ppycHG3btk333HPPtU0LABg0YvoeUGNjo5qbm1VcXBx5LBAIqLCwULW1tT2u6ezsVDgcjtoAAINfTAPU3NwsScrJyYl6PCcnJ/LcV1VUVCgQCES2vLy8WI4EABigzD8FV15erra2tsjW1NRkPRIAoB/ENEDBYFCS1NLSEvV4S0tL5Lmv8vv9Sk9Pj9oAAINfTAOUn5+vYDCoqqqqyGPhcFj79+9XUVFRLA8FAEhwnj8Fd/bsWdXX10e+bmxs1OHDh5WZmanRo0drxYoV+vWvf61bbrlF+fn5evLJJxUKhTR//vxYzg0ASHCeA3TgwAHdddddka9XrVolSVq8eLE2btyoxx57TB0dHXrooYfU2tqqO+64Qzt37tTQoUNjNzUAIOF5DtDMmTPlnOv1eZ/Pp6efflpPP/30NQ02kH3698M8r8lOHh6HSYCBY8hNoz2v+YfMf4vDJFca1vjffVrHLUzjy/xTcACA6xMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMeL4bNqQhN7f3y3EufJLRL8cBYqHphRs8r5nu7/a85pXwKM9r1Br2vgZxxxUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5EOYNkHvN+oEYNXctYIz2taFo3v07Ey//GE5zU141/pw5GGel6xvnK+5zXZLX/0vAbxxxUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5EOYOczvf/54IY4zBFL3Xf+H89rXLLP85qmYr/nNZJ0MdTleU1S6iXPa/79zpc8r0nxfhrUfKlv5+HJ/7/A85r/6vZ+89zhSd7PXc7+ds9rnOcV6A9cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZaR90XkjxvKa7D7dD3PCr33pe82/Lb/e8pj89PuJfPa9Jkve7cJ53Fz2vkaSTl7zfHPNfPpvpeU3x7hWe12QcSvW8JvffWzyvkSTfpyc8r/ns42Ge1+Qke7/5q/vTf3heg4GJKyAAgAkCBAAw4TlAe/fu1dy5cxUKheTz+bRt27ao55csWSKfzxe1zZkzJ1bzAgAGCc8B6ujoUEFBgSorK3vdZ86cOTp16lRke+ONN65pSADA4OP5QwilpaUqLS392n38fr+CwWCfhwIADH5xeQ+ourpa2dnZmjBhgpYtW6YzZ870um9nZ6fC4XDUBgAY/GIeoDlz5ui1115TVVWVnn32WdXU1Ki0tFSXevl4a0VFhQKBQGTLy8uL9UgAgAEo5j8HdM8990R+fdttt2ny5MkaN26cqqurNWvWrCv2Ly8v16pVqyJfh8NhIgQA14G4fwx77NixysrKUn19fY/P+/1+paenR20AgMEv7gE6ceKEzpw5o9zc3HgfCgCQQDz/FdzZs2ejrmYaGxt1+PBhZWZmKjMzU2vXrtWiRYsUDAbV0NCgxx57TDfffLNKSkpiOjgAILF5DtCBAwd01113Rb7+8v2bxYsXa/369Tpy5Ih+//vfq7W1VaFQSLNnz9Yzzzwjv98fu6kBAAnP55zzfpfMOAqHwwoEApqpeRri837Tz4GqsaLI85q8qf8Zh0kSz2fvjfK8ZsT/836TS0lK3fmnPq0bbP7z8b/zvOb//vO/eF6z+exIz2tem8CHlAa6L1yXqrVdbW1tX/u+PveCAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImY/5Pc6Fl+ea31CAkrV8etR7juDJ/xWb8c54n3F3leM14fxmESWOAKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IAZgZs91ZjwBDXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwMsR4AwOCQ7PP+59n/Hp/ieU3wPc9LMEBxBQQAMEGAAAAmPAWooqJCU6dOVVpamrKzszV//nzV1dVF7XPhwgWVlZVpxIgRuvHGG7Vo0SK1tLTEdGgAQOLzFKCamhqVlZVp37592rVrl7q6ujR79mx1dHRE9lm5cqXeeecdbdmyRTU1NTp58qQWLlwY88EBAInN04cQdu7cGfX1xo0blZ2drYMHD2rGjBlqa2vTK6+8ok2bNulHP/qRJGnDhg36zne+o3379ukHP/hB7CYHACS0a3oPqK2tTZKUmZkpSTp48KC6urpUXFwc2WfixIkaPXq0amtre/wenZ2dCofDURsAYPDrc4C6u7u1YsUKTZ8+XZMmTZIkNTc3KzU1VRkZGVH75uTkqLm5ucfvU1FRoUAgENny8vL6OhIAIIH0OUBlZWU6evSoNm/efE0DlJeXq62tLbI1NTVd0/cDACSGPv0g6vLly7Vjxw7t3btXo0aNijweDAZ18eJFtba2Rl0FtbS0KBgM9vi9/H6//H5/X8YAACQwT1dAzjktX75cW7du1Z49e5Sfnx/1/JQpU5SSkqKqqqrIY3V1dTp+/LiKiopiMzEAYFDwdAVUVlamTZs2afv27UpLS4u8rxMIBDRs2DAFAgE9+OCDWrVqlTIzM5Wenq5HHnlERUVFfAIOABDFU4DWr18vSZo5c2bU4xs2bNCSJUskSb/97W+VlJSkRYsWqbOzUyUlJfrd734Xk2EBAIOHpwA55666z9ChQ1VZWanKyso+DwUg8Vxy3d4XcTOw6xr/+wEAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCiT/8iKgDEwrmp56xHgCGugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFEBMJPv48yy84RUDADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqQArtC5e6TnNZdu747DJBjMuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz4nHPOeoi/FQ6HFQgENFPzNMSXYj0OAMCjL1yXqrVdbW1tSk9P73U/roAAACYIEADAhKcAVVRUaOrUqUpLS1N2drbmz5+vurq6qH1mzpwpn88XtT388MMxHRoAkPg8BaimpkZlZWXat2+fdu3apa6uLs2ePVsdHR1R+y1dulSnTp2KbOvWrYvp0ACAxOfpX0TduXNn1NcbN25Udna2Dh48qBkzZkQeHz58uILBYGwmBAAMStf0HlBbW5skKTMzM+rx119/XVlZWZo0aZLKy8t17ty5Xr9HZ2enwuFw1AYAGPw8XQH9re7ubq1YsULTp0/XpEmTIo/fd999GjNmjEKhkI4cOaLHH39cdXV1evvtt3v8PhUVFVq7dm1fxwAAJKg+/xzQsmXL9N577+mDDz7QqFGjet1vz549mjVrlurr6zVu3Lgrnu/s7FRnZ2fk63A4rLy8PH4OCAAS1Df9OaA+XQEtX75cO3bs0N69e782PpJUWFgoSb0GyO/3y+/392UMAEAC8xQg55weeeQRbd26VdXV1crPz7/qmsOHD0uScnNz+zQgAGBw8hSgsrIybdq0Sdu3b1daWpqam5slSYFAQMOGDVNDQ4M2bdqkH//4xxoxYoSOHDmilStXasaMGZo8eXJc/gMAAInJ03tAPp+vx8c3bNigJUuWqKmpST/96U919OhRdXR0KC8vTwsWLNATTzzxtX8P+Le4FxwAJLa4vAd0tVbl5eWppqbGy7cEAFynuBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDEEOsBvso5J0n6Ql2SMx4GAODZF+qS9Nffz3sz4ALU3t4uSfpA7xpPAgC4Fu3t7QoEAr0+73NXS1Q/6+7u1smTJ5WWliafzxf1XDgcVl5enpqampSenm40oT3Ow2Wch8s4D5dxHi4bCOfBOaf29naFQiElJfX+Ts+AuwJKSkrSqFGjvnaf9PT06/oF9iXOw2Wch8s4D5dxHi6zPg9fd+XzJT6EAAAwQYAAACYSKkB+v19r1qyR3++3HsUU5+EyzsNlnIfLOA+XJdJ5GHAfQgAAXB8S6goIADB4ECAAgAkCBAAwQYAAACYSJkCVlZW66aabNHToUBUWFurDDz+0HqnfPfXUU/L5fFHbxIkTrceKu71792ru3LkKhULy+Xzatm1b1PPOOa1evVq5ubkaNmyYiouLdezYMZth4+hq52HJkiVXvD7mzJljM2ycVFRUaOrUqUpLS1N2drbmz5+vurq6qH0uXLigsrIyjRgxQjfeeKMWLVqklpYWo4nj45uch5kzZ17xenj44YeNJu5ZQgTozTff1KpVq7RmzRp99NFHKigoUElJiU6fPm09Wr+79dZbderUqcj2wQcfWI8Udx0dHSooKFBlZWWPz69bt04vvviiXn75Ze3fv1833HCDSkpKdOHChX6eNL6udh4kac6cOVGvjzfeeKMfJ4y/mpoalZWVad++fdq1a5e6uro0e/ZsdXR0RPZZuXKl3nnnHW3ZskU1NTU6efKkFi5caDh17H2T8yBJS5cujXo9rFu3zmjiXrgEMG3aNFdWVhb5+tKlSy4UCrmKigrDqfrfmjVrXEFBgfUYpiS5rVu3Rr7u7u52wWDQPffcc5HHWltbnd/vd2+88YbBhP3jq+fBOecWL17s5s2bZzKPldOnTztJrqamxjl3+f99SkqK27JlS2Sfjz/+2ElytbW1VmPG3VfPg3PO/fCHP3Q///nP7Yb6Bgb8FdDFixd18OBBFRcXRx5LSkpScXGxamtrDSezcezYMYVCIY0dO1b333+/jh8/bj2SqcbGRjU3N0e9PgKBgAoLC6/L10d1dbWys7M1YcIELVu2TGfOnLEeKa7a2tokSZmZmZKkgwcPqqurK+r1MHHiRI0ePXpQvx6+eh6+9PrrrysrK0uTJk1SeXm5zp07ZzFerwbczUi/6vPPP9elS5eUk5MT9XhOTo4++eQTo6lsFBYWauPGjZowYYJOnTqltWvX6s4779TRo0eVlpZmPZ6J5uZmSerx9fHlc9eLOXPmaOHChcrPz1dDQ4N+9atfqbS0VLW1tUpOTrYeL+a6u7u1YsUKTZ8+XZMmTZJ0+fWQmpqqjIyMqH0H8+uhp/MgSffdd5/GjBmjUCikI0eO6PHHH1ddXZ3efvttw2mjDfgA4a9KS0sjv548ebIKCws1ZswYvfXWW3rwwQcNJ8NAcM8990R+fdttt2ny5MkaN26cqqurNWvWLMPJ4qOsrExHjx69Lt4H/Tq9nYeHHnoo8uvbbrtNubm5mjVrlhoaGjRu3Lj+HrNHA/6v4LKyspScnHzFp1haWloUDAaNphoYMjIyNH78eNXX11uPYubL1wCvjyuNHTtWWVlZg/L1sXz5cu3YsUPvv/9+1D/fEgwGdfHiRbW2tkbtP1hfD72dh54UFhZK0oB6PQz4AKWmpmrKlCmqqqqKPNbd3a2qqioVFRUZTmbv7NmzamhoUG5urvUoZvLz8xUMBqNeH+FwWPv377/uXx8nTpzQmTNnBtXrwzmn5cuXa+vWrdqzZ4/y8/Ojnp8yZYpSUlKiXg91dXU6fvz4oHo9XO089OTw4cOSNLBeD9afgvgmNm/e7Px+v9u4caP785//7B566CGXkZHhmpubrUfrV7/4xS9cdXW1a2xsdH/4wx9ccXGxy8rKcqdPn7YeLa7a29vdoUOH3KFDh5wk9/zzz7tDhw65Tz/91Dnn3G9+8xuXkZHhtm/f7o4cOeLmzZvn8vPz3fnz540nj62vOw/t7e3u0UcfdbW1ta6xsdHt3r3bfe9733O33HKLu3DhgvXoMbNs2TIXCARcdXW1O3XqVGQ7d+5cZJ+HH37YjR492u3Zs8cdOHDAFRUVuaKiIsOpY+9q56G+vt49/fTT7sCBA66xsdFt377djR071s2YMcN48mgJESDnnHvppZfc6NGjXWpqqps2bZrbt2+f9Uj97u6773a5ubkuNTXVffvb33Z33323q6+vtx4r7t5//30n6Ypt8eLFzrnLH8V+8sknXU5OjvP7/W7WrFmurq7Odug4+LrzcO7cOTd79mw3cuRIl5KS4saMGeOWLl066P6Q1tN/vyS3YcOGyD7nz593P/vZz9y3vvUtN3z4cLdgwQJ36tQpu6Hj4Grn4fjx427GjBkuMzPT+f1+d/PNN7tf/vKXrq2tzXbwr+CfYwAAmBjw7wEBAAYnAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDE/wB3z3opkp0DGwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Print the new label\n",
    "print(y_train_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praveenbhandari/Desktop/mlp/mlp/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation = 'relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model.fit(X_train,y_train_one_hot, validation_data=(X_test,y_test_one_hot), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron():\n",
    "    def __init__(self,bias):\n",
    "        self.bias=bias\n",
    "        self.weights=[]\n",
    "\n",
    "    # def sigmoid(self,x):\n",
    "    #     return 1/(1+np.exp(-x))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -100, 100)))  # Clipping inputs to avoid large values\n",
    "\n",
    "    \n",
    "    def sum_input_to_hiddedn(self):\n",
    "        sum=0\n",
    "        for i in range(len(self.input)):\n",
    "            sum += self.input[i]*self.weights[i]\n",
    "            # print(sum)\n",
    "        return sum+self.bias\n",
    "    \n",
    "    \n",
    "\n",
    "    def cost(self,input):\n",
    "        self.input=input\n",
    "        self.output=self.sigmoid(self.sum_input_to_hiddedn())\n",
    "        # print(self.output)\n",
    "        return self.output\n",
    "    \n",
    "    def cal_error(self,target_op):\n",
    "        return 0.5*np.square(target_op-self.output)\n",
    "    \n",
    "    def error_wrt_output(self, targer_op):\n",
    "        return -(targer_op-self.output)\n",
    "\n",
    "\n",
    "    def error_wrt_input(self):\n",
    "        return self.output*(1-self.output)\n",
    "\n",
    "    def total_error(self,targer_op):\n",
    "        return self.error_wrt_input()*self.error_wrt_output(targer_op)\n",
    "    \n",
    "\n",
    "    # def error_wrt_weight(self,index):\n",
    "    #     return self.input[index]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "    def __init__(self,hidden_layer,bias):\n",
    "        self.network=[]\n",
    "        self.bias = bias if bias is not None else random.random()\n",
    "        for _ in range(hidden_layer):\n",
    "            self.network.append(neuron(self.bias))\n",
    "\n",
    "    def forward(self,input):\n",
    "        outputs=[]\n",
    "        for i in self.network:\n",
    "            outputs.append(i.cost(input))\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "    # def backPropogation(self,):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class all_network():\n",
    "    def __init__(self,n_input_layer,n_hidden_layer,n_output_layer,hidden_weights,output_weights,hidden_bias,output_bias):\n",
    "        self.hidden_l_network=network(n_hidden_layer,hidden_bias)\n",
    "        self.output_l_network=network(n_output_layer,output_bias)\n",
    "        self.n_input_layer=n_input_layer\n",
    "        # self.hidden_weight_layer=self.add_weights_to_hidden(hidden_weights)\n",
    "        # self.output_weight_layer=self.add_weights_to_output(output_weights)\n",
    "        self.add_weights(self.hidden_l_network,hidden_weights,n_input_layer)\n",
    "        self.add_weights(self.output_l_network,output_weights,n_hidden_layer)\n",
    "\n",
    "\n",
    "    def add_weights(self, layer, weights, num_inputs):\n",
    "        count = 0\n",
    "        for neuron in layer.network:\n",
    "            neuron.weights = weights[count:count + num_inputs]\n",
    "            count += num_inputs\n",
    "    # def add_weights_to_output(self,output_weights):\n",
    "    #     count=0\n",
    "    #     for i in range(len(self.output_l_network.network)):\n",
    "    #         # print(hidden_l_network.network[i].weight)\n",
    "    #         for j in range((self.n_input_layer)):\n",
    "    #             self.output_l_network.network[i].weight.append(output_weights[count])\n",
    "    #             count+=1\n",
    "\n",
    "    def forward_hidden_op(self,input_data):\n",
    "        # hidden_op=self.hidden_l_network.forward(input_data)\n",
    "        # self.hidden_l_cost=self.hidden_l_network.forward(input_data)\n",
    "        # print(\"Hidden layer outputs:\", self.hidden_l_cost)\n",
    "        # self.output_l_cost=self.output_l_network.forward(self.hidden_l_cost)\n",
    "        # print(\"Output layer outputs:\", self.output_l_cost)  # Print output layer outputs\n",
    "        hidden_output = self.hidden_l_network.forward(input_data)\n",
    "        # print(f\"Hidden Layer Output: {hidden_output}\")\n",
    "        output = self.output_l_network.forward(hidden_output)\n",
    "        # print(f\"Output Layer Output: {output}\")\n",
    "\n",
    "        # return np.mean(output)\n",
    "        return output\n",
    "    \n",
    "    def backPropogation(self, input_data, target_op,learning_rate=0.5):\n",
    "        # Output layer deltas\n",
    "        # self.forward_hidden_op(target_inp)\n",
    "        hidden_output = self.hidden_l_network.forward(input_data)\n",
    "        final_output = self.output_l_network.forward(hidden_output)\n",
    "\n",
    "        # output_deltas = [0] * len(self.output_l_network.network)\n",
    "        # for i in range(len(self.output_l_network.network)):\n",
    "        #     output_deltas[i] = self.output_l_network.network[i].cal_error(target_op[i])\n",
    "\n",
    "        # output_deltas = []\n",
    "        output_deltas = [\n",
    "            (target - output) * neuron.error_wrt_input()\n",
    "            for target, output, neuron in zip(target_op, final_output, self.output_l_network.network)\n",
    "        ]\n",
    "        # hidden_deltas=[]\n",
    "        \n",
    "        # Hidden layer deltas\n",
    "        hidden_deltas = []\n",
    "        for i, hidden_neuron in enumerate(self.hidden_l_network.network):\n",
    "            weighted_sum = sum(\n",
    "                delta * output_neuron.weights[i]\n",
    "                for delta, output_neuron in zip(output_deltas, self.output_l_network.network)\n",
    "            )\n",
    "            hidden_deltas.append(weighted_sum * hidden_neuron.error_wrt_input())\n",
    "\n",
    "        # Update output layer weights and biases\n",
    "        for neuron, delta in zip(self.output_l_network.network, output_deltas):\n",
    "            neuron.weights = [\n",
    "                weight + learning_rate * delta * hidden_output[i]\n",
    "                for i, weight in enumerate(neuron.weights)\n",
    "            ]\n",
    "            neuron.bias += learning_rate * delta\n",
    "\n",
    "        # Update hidden layer weights and biases\n",
    "        for neuron, delta in zip(self.hidden_l_network.network, hidden_deltas):\n",
    "            neuron.weights = [\n",
    "                weight + learning_rate * delta * input_data[i]\n",
    "                for i, weight in enumerate(neuron.weights)\n",
    "            ]\n",
    "            neuron.bias += learning_rate * delta\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_total_error(self, dataset):\n",
    "        total_error = 0\n",
    "        for input_data, target_op in dataset:\n",
    "            outputs = self.forward_hidden_op(input_data)\n",
    "            total_error += sum(0.5 * (target_op[i] - outputs[i]) ** 2 for i in range(len(target_op)))\n",
    "        return total_error\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class probabilities: [0.49460936 0.50539064]\n"
     ]
    }
   ],
   "source": [
    "nn = all_network(2, 2, 2, hidden_weights=[0.15, 0.2, 0.25, 0.3], hidden_bias=0.35, output_weights=[0.4, 0.45, 0.5, 0.55], output_bias=0.6)\n",
    "a=nn.forward_hidden_op([0.05, 0.1])\n",
    "exp_logits = np.exp(a - np.max(a))  # Normalize for numerical stability\n",
    "probabilities = exp_logits / np.sum(exp_logits)\n",
    "print(\"Class probabilities:\", probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from network: [np.float64(0.9325486342326953), np.float64(0.9439366660089503), np.float64(0.9479151672367985)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Instantiate the expanded network\n",
    "nn = all_network(\n",
    "    n_input_layer=5,\n",
    "    n_hidden_layer=4,  # First hidden layer\n",
    "    n_output_layer=3,  # Second hidden layer\n",
    "    hidden_weights=np.random.rand(20).tolist(),  # 4 neurons * 5 inputs\n",
    "    hidden_bias=0.5,   # Bias for each hidden layer neuron\n",
    "    output_weights=np.random.rand(12).tolist(), # 3 neurons * 4 inputs\n",
    "    output_bias=0.6    # Bias for each output layer neuron\n",
    ")\n",
    "\n",
    "# Input data\n",
    "input_data = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "# Perform forward propagation\n",
    "output = nn.forward_hidden_op(input_data)\n",
    "\n",
    "# Display the output\n",
    "print(\"Output from network:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Outputs:\n",
      "[np.float64(0.7513650695523157), np.float64(0.7729284653214625)]\n",
      "\n",
      "Updated Hidden Layer Weights and Biases:\n",
      "Neuron 1: Weights=[np.float64(0.1497807161327628), np.float64(0.19956143226552567)], Bias=0.3456143226552565\n",
      "Neuron 2: Weights=[np.float64(0.24975114363236958), np.float64(0.29950228726473915)], Bias=0.3450228726473914\n",
      "\n",
      "Updated Output Layer Weights and Biases:\n",
      "Neuron 1: Weights=[np.float64(0.35891647971788465), np.float64(0.4086661860762334)], Bias=0.5307507191857215\n",
      "Neuron 2: Weights=[np.float64(0.5113012702387375), np.float64(0.5613701211079891)], Bias=0.6190491182582781\n",
      "\n",
      "Outputs After Training:\n",
      "[np.float64(0.7284417622337656), np.float64(0.7783769203009705)]\n"
     ]
    }
   ],
   "source": [
    "# Define a small dataset for testing\n",
    "input_data = [0.05, 0.1]  # Input to the network\n",
    "target_op = [0.01, 0.99]  # Desired output from the network\n",
    "\n",
    "# Define initial weights and biases\n",
    "hidden_weights = [0.15, 0.2, 0.25, 0.3]  # Weights connecting input to hidden layer\n",
    "output_weights = [0.4, 0.45, 0.5, 0.55]  # Weights connecting hidden to output layer\n",
    "hidden_bias = 0.35  # Bias for hidden layer neurons\n",
    "output_bias = 0.6   # Bias for output layer neurons\n",
    "\n",
    "# Create the neural network\n",
    "nn = all_network(\n",
    "    n_input_layer=2,\n",
    "    n_hidden_layer=2,\n",
    "    n_output_layer=2,\n",
    "    hidden_weights=hidden_weights,\n",
    "    hidden_bias=hidden_bias,\n",
    "    output_weights=output_weights,\n",
    "    output_bias=output_bias\n",
    ")\n",
    "\n",
    "# Print initial outputs (before training)\n",
    "print(\"Initial Outputs:\")\n",
    "initial_output = nn.forward_hidden_op(input_data)\n",
    "print(initial_output)\n",
    "\n",
    "# Perform one step of backpropagation\n",
    "learning_rate = 0.5\n",
    "nn.backPropogation(input_data, target_op, learning_rate)\n",
    "\n",
    "# Print updated weights and biases\n",
    "print(\"\\nUpdated Hidden Layer Weights and Biases:\")\n",
    "for i, neuron in enumerate(nn.hidden_l_network.network):\n",
    "    print(f\"Neuron {i + 1}: Weights={neuron.weights}, Bias={neuron.bias}\")\n",
    "\n",
    "print(\"\\nUpdated Output Layer Weights and Biases:\")\n",
    "for i, neuron in enumerate(nn.output_l_network.network):\n",
    "    print(f\"Neuron {i + 1}: Weights={neuron.weights}, Bias={neuron.bias}\")\n",
    "\n",
    "# Print outputs after training\n",
    "print(\"\\nOutputs After Training:\")\n",
    "updated_output = nn.forward_hidden_op(input_data)\n",
    "print(updated_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the XOR problem...\n",
      "Epoch 0, Total Error: 1.312864\n",
      "Epoch 100, Total Error: 0.952046\n",
      "Epoch 200, Total Error: 0.956877\n",
      "Epoch 300, Total Error: 0.959967\n",
      "Epoch 400, Total Error: 0.961817\n",
      "Epoch 500, Total Error: 0.962546\n",
      "Epoch 600, Total Error: 0.960888\n",
      "Epoch 700, Total Error: 0.948675\n",
      "Epoch 800, Total Error: 0.887187\n",
      "Epoch 900, Total Error: 0.762480\n",
      "\n",
      "Testing the XOR problem...\n",
      "Input: [0, 0], Predicted Output: [np.float64(0.17185679895761477), np.float64(0.8320557146467397)]\n",
      "Input: [0, 1], Predicted Output: [np.float64(0.6258499406911979), np.float64(0.3708986021273134)]\n",
      "Input: [1, 0], Predicted Output: [np.float64(0.6318516245795388), np.float64(0.3688753220628999)]\n",
      "Input: [1, 1], Predicted Output: [np.float64(0.6383103467889611), np.float64(0.35424198726289746)]\n"
     ]
    }
   ],
   "source": [
    "# XOR dataset\n",
    "xor_inputs = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "]\n",
    "\n",
    "xor_targets = [\n",
    "    [0, 1],  # Output for [0, 0]\n",
    "    [1, 0],  # Output for [0, 1]\n",
    "    [1, 0],  # Output for [1, 0]\n",
    "    [0, 1]   # Output for [1, 1]\n",
    "]\n",
    "\n",
    "# Initialize weights and biases\n",
    "hidden_weights = [0.1, 0.2, 0.3, 0.4]  # Random initialization\n",
    "output_weights = [0.5, 0.6, 0.7, 0.8]\n",
    "hidden_bias = 0.35\n",
    "output_bias = 0.6\n",
    "\n",
    "# Create the network\n",
    "nn = all_network(\n",
    "    n_input_layer=2,\n",
    "    n_hidden_layer=2,\n",
    "    n_output_layer=2,\n",
    "    hidden_weights=hidden_weights,\n",
    "    hidden_bias=hidden_bias,\n",
    "    output_weights=output_weights,\n",
    "    output_bias=output_bias\n",
    ")\n",
    "\n",
    "# Train the network on the XOR problem\n",
    "learning_rate = 0.5\n",
    "epochs = 1000  # Number of training iterations\n",
    "\n",
    "print(\"Training the XOR problem...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_error = 0\n",
    "    for input_data, target_op in zip(xor_inputs, xor_targets):\n",
    "        nn.backPropogation(input_data, target_op, learning_rate)\n",
    "        total_error += nn.calculate_total_error([(input_data, target_op)])\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Total Error: {total_error:.6f}\")\n",
    "\n",
    "# Test the network\n",
    "print(\"\\nTesting the XOR problem...\")\n",
    "for input_data in xor_inputs:\n",
    "    output = nn.forward_hidden_op(input_data)\n",
    "    print(f\"Input: {input_data}, Predicted Output: {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: 3\n",
      "\n",
      "Training the network on MNIST data...\n",
      "Epoch 1/5, Total Error: 9139.620941\n",
      "Epoch 2/5, Total Error: 2195.848908\n",
      "Epoch 3/5, Total Error: 1924.854084\n",
      "Epoch 4/5, Total Error: 1782.671257\n",
      "Epoch 5/5, Total Error: 1668.967155\n",
      "\n",
      "Accuracy on MNIST test data: 93.80%\n",
      "Prediction after training: 7\n",
      "Actual class: 7\n",
      "after train [np.float64(0.9681478106756721), np.float64(0.9654559298175209), np.float64(0.9559403131723999), np.float64(0.9712328651655572), np.float64(0.9690818226041124), np.float64(0.9564146843861848), np.float64(0.963861185789479), np.float64(0.9665142734788169), np.float64(0.9640462778014949), np.float64(0.9555501801353329)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train\n",
    "y_train = y_train\n",
    "X_test = X_test\n",
    "y_test = y_test\n",
    "X_train_1 = X_train[:1000]\n",
    "y_train_1 = y_train[:1000]\n",
    "X_test_1 = X_test[:1000]\n",
    "y_test_1 = y_test[:1000]\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0  # Normalize and flatten\n",
    "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
    "y_train_onehot = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_onehot = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Initialize the network\n",
    "input_size = 784\n",
    "hidden_layer_size = 64\n",
    "output_layer_size = 10\n",
    "\n",
    "hidden_weights = np.random.rand(hidden_layer_size * input_size) * 0.1\n",
    "output_weights = np.random.rand(output_layer_size * hidden_layer_size) * 0.1\n",
    "hidden_bias = 0.1\n",
    "output_bias = 0.1\n",
    "\n",
    "nn = all_network(\n",
    "    n_input_layer=input_size,\n",
    "    n_hidden_layer=hidden_layer_size,\n",
    "    n_output_layer=output_layer_size,\n",
    "    hidden_weights=hidden_weights.tolist(),\n",
    "    hidden_bias=hidden_bias,\n",
    "    output_weights=output_weights.tolist(),\n",
    "    output_bias=output_bias\n",
    ")\n",
    "\n",
    "# Train the network\n",
    "epochs = 5\n",
    "learning_rate = 0.1\n",
    "batch_size = 32\n",
    "output = nn.forward_hidden_op(X_test[0])\n",
    "predicted_class = np.argmax(output)\n",
    "print(\"Prediction before training:\", predicted_class)\n",
    "print(\"\\nTraining the network on MNIST data...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_error = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train_onehot[i:i+batch_size]\n",
    "        for input_data, target_output in zip(batch_X, batch_y):\n",
    "            nn.backPropogation(input_data.tolist(), target_output.tolist(), learning_rate)\n",
    "            total_error += nn.calculate_total_error([(input_data.tolist(), target_output.tolist())])\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Total Error: {total_error:.6f}\")\n",
    "\n",
    "# Test the network\n",
    "correct_predictions = 0\n",
    "for input_data, target_label in zip(X_test, y_test):\n",
    "    predicted_output = nn.forward_hidden_op(input_data.tolist())\n",
    "    predicted_class = predicted_output.index(max(predicted_output))\n",
    "    if predicted_class == target_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(X_test)\n",
    "print(f\"\\nAccuracy on MNIST test data: {accuracy * 100:.2f}%\")\n",
    "output_after_training = nn.forward_hidden_op(X_test[0])\n",
    "predicted_class_after_training = np.argmax(output_after_training)\n",
    "\n",
    "# Print the network's prediction after training\n",
    "print(\"Prediction after training:\", predicted_class_after_training)\n",
    "\n",
    "# Print the actual target class\n",
    "actual_class = np.argmax(y_test_onehot[0])\n",
    "print(\"Actual class:\", actual_class)\n",
    "print(\"after train\",output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open(\"mnist_network_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(nn, file)\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class: 7\n",
      "after train [np.float64(0.9569208496791848), np.float64(0.9621703502679856), np.float64(0.9626856005098301), np.float64(0.9721810422144805), np.float64(0.9565162256581629), np.float64(0.9523248661276887), np.float64(0.9576968712211601), np.float64(0.9445013860547323), np.float64(0.9643497251120839), np.float64(0.9640974021710926)]\n"
     ]
    }
   ],
   "source": [
    "# Print the actual target class\n",
    "actual_class = np.argmax(y_test_onehot[0])\n",
    "print(\"Actual class:\", actual_class)\n",
    "print(\"after train\",output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x141d00a70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: 6\n",
      "Prediction after training: 6\n",
      "Actual class: 5\n"
     ]
    }
   ],
   "source": [
    "input_sample = X_train[0]\n",
    "target_sample = y_train_onehot[0]\n",
    "\n",
    "# Forward pass\n",
    "output = nn.forward_hidden_op(input_sample)\n",
    "\n",
    "# Print the network's prediction before training\n",
    "predicted_class = np.argmax(output)\n",
    "print(\"Prediction before training:\", predicted_class)\n",
    "\n",
    "# Perform backpropagation\n",
    "nn.backPropogation(input_sample, target_sample, learning_rate=0.1)\n",
    "\n",
    "# Forward pass again after backpropagation\n",
    "output_after_training = nn.forward_hidden_op(input_sample)\n",
    "predicted_class_after_training = np.argmax(output_after_training)\n",
    "\n",
    "# Print the network's prediction after training\n",
    "print(\"Prediction after training:\", predicted_class_after_training)\n",
    "\n",
    "# Print the actual target class\n",
    "actual_class = np.argmax(target_sample)\n",
    "print(\"Actual class:\", actual_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.shape\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1327eab40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.78521205, 0.78521205, 0.78521205, 0.78521205, 0.91346952,\n",
       "        0.91514751, 0.91517588, 0.91519337, 0.91519339, 0.91519339,\n",
       "        0.91519339, 0.91519339, 0.91519339, 0.91519339, 0.91519339,\n",
       "        0.91519339, 0.91519339, 0.91519339, 0.91519339, 0.91519339,\n",
       "        0.91514659, 0.91515738, 0.91513378, 0.91351347, 0.78521205,\n",
       "        0.78521205, 0.78521205, 0.78521205]),\n",
       " array([0.80338478, 0.80338478, 0.80338478, 0.80338478, 0.92967899,\n",
       "        0.93023925, 0.93025007, 0.93026304, 0.93026305, 0.93026305,\n",
       "        0.93026305, 0.93026305, 0.93026305, 0.93026305, 0.93026305,\n",
       "        0.93026305, 0.93026305, 0.93026305, 0.93026305, 0.93026305,\n",
       "        0.93024994, 0.930253  , 0.93024661, 0.92968616, 0.80338478,\n",
       "        0.80338478, 0.80338478, 0.80338478]),\n",
       " array([0.79815573, 0.79815573, 0.79815573, 0.79815573, 0.92547699,\n",
       "        0.92607347, 0.92608563, 0.92610212, 0.92610213, 0.92610213,\n",
       "        0.92610213, 0.92610213, 0.92610213, 0.92610213, 0.92610213,\n",
       "        0.92610213, 0.92610213, 0.92610213, 0.92610213, 0.92610213,\n",
       "        0.92609657, 0.92609761, 0.92609326, 0.92521997, 0.79815573,\n",
       "        0.79815573, 0.79815573, 0.79815573]),\n",
       " array([0.79268105, 0.79268105, 0.79268105, 0.79268105, 0.92053624,\n",
       "        0.92157159, 0.92158703, 0.9215946 , 0.92159461, 0.92159461,\n",
       "        0.92159461, 0.92159461, 0.92159461, 0.92159461, 0.92159461,\n",
       "        0.92159461, 0.92159461, 0.92159461, 0.92159461, 0.92159461,\n",
       "        0.9215499 , 0.92156017, 0.92153735, 0.9199565 , 0.79268105,\n",
       "        0.79268105, 0.79268105, 0.79268105]),\n",
       " array([0.8268333 , 0.8268333 , 0.8268333 , 0.8268333 , 0.94636957,\n",
       "        0.9471961 , 0.94720964, 0.94722208, 0.94722209, 0.94722209,\n",
       "        0.94722209, 0.94722209, 0.94722209, 0.94722209, 0.94722209,\n",
       "        0.94722209, 0.94722209, 0.94722209, 0.94722209, 0.94722209,\n",
       "        0.94719443, 0.9472008 , 0.94718677, 0.94616481, 0.8268333 ,\n",
       "        0.8268333 , 0.8268333 , 0.8268333 ]),\n",
       " array([0.81195407, 0.81195407, 0.81195407, 0.81195407, 0.93601992,\n",
       "        0.93676614, 0.93677745, 0.93678022, 0.93678023, 0.93678023,\n",
       "        0.93678023, 0.93678023, 0.93678023, 0.93678023, 0.93678023,\n",
       "        0.93678023, 0.93678023, 0.93678023, 0.93678023, 0.93678023,\n",
       "        0.93676681, 0.93676962, 0.93676104, 0.93559705, 0.81195407,\n",
       "        0.81195407, 0.81195407, 0.81195407]),\n",
       " array([0.81459594, 0.81459594, 0.81459594, 0.81459594, 0.93791055,\n",
       "        0.93868967, 0.93870291, 0.93871461, 0.93871463, 0.93871463,\n",
       "        0.93871463, 0.93871463, 0.93871463, 0.93871463, 0.93871463,\n",
       "        0.93871463, 0.93871463, 0.93871463, 0.93871463, 0.93871463,\n",
       "        0.93868767, 0.93869376, 0.93867934, 0.93750011, 0.81459594,\n",
       "        0.81459594, 0.81459594, 0.81459594]),\n",
       " array([0.82112086, 0.82112086, 0.82112086, 0.82112086, 0.94250186,\n",
       "        0.94331542, 0.9433293 , 0.94334287, 0.94334288, 0.94334288,\n",
       "        0.94334288, 0.94334288, 0.94334288, 0.94334288, 0.94334288,\n",
       "        0.94334288, 0.94334288, 0.94334288, 0.94334288, 0.94334288,\n",
       "        0.94331156, 0.94331877, 0.94330291, 0.94226139, 0.82112086,\n",
       "        0.82112086, 0.82112086, 0.82112086]),\n",
       " array([0.80444375, 0.80444375, 0.80444375, 0.80444375, 0.93022874,\n",
       "        0.93106776, 0.93108123, 0.93108864, 0.93108864, 0.93108864,\n",
       "        0.93108864, 0.93108864, 0.93108864, 0.93108864, 0.93108864,\n",
       "        0.93108864, 0.93108864, 0.93108864, 0.93108864, 0.93108864,\n",
       "        0.93107913, 0.93108129, 0.93107629, 0.9305202 , 0.80444375,\n",
       "        0.80444375, 0.80444375, 0.80444375]),\n",
       " array([0.82914072, 0.82914072, 0.82914072, 0.82914072, 0.94813335,\n",
       "        0.94872805, 0.94873628, 0.94874376, 0.94874376, 0.94874376,\n",
       "        0.94874376, 0.94874376, 0.94874376, 0.94874376, 0.94874376,\n",
       "        0.94874376, 0.94874376, 0.94874376, 0.94874376, 0.94874376,\n",
       "        0.94871681, 0.94872292, 0.94870861, 0.94758607, 0.82914072,\n",
       "        0.82914072, 0.82914072, 0.82914072])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def __init__(self,n_input_layer,n_hidden_layer,n_output_layer,hidden_weights,output_weights,hidden_bias,output_bias):\n",
    "\n",
    "hidden_weights=np.random.rand(764 * 50) * 0.1\n",
    "output_weight=np.random.rand(10 * 50) * 0.1\n",
    "\n",
    "nn = all_network(764, 50, 10, hidden_weights, hidden_bias=0.1, output_weights=output_weight, output_bias=0.1)\n",
    "a=nn.forward_hidden_op(X_train[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "a=np.array(a)\n",
    "class_predictions = a.argmax()\n",
    "value=class_predictions\n",
    "min_value = 1\n",
    "max_value = 10\n",
    "normalized_value = min_value + (value - np.min([value, min_value])) * (max_value - min_value) / (np.max([value, max_value]) - np.min([value, min_value]))\n",
    "\n",
    "print(normalized_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.uint8' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Perform forward and backward pass\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     nn\u001b[38;5;241m.\u001b[39mforward_hidden_op(input_data)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackPropogation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate total error for the epoch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m total_error \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mcalculate_total_error(\u001b[38;5;28mzip\u001b[39m(X_train, y_train))\n",
      "Cell \u001b[0;32mIn[25], line 51\u001b[0m, in \u001b[0;36mall_network.backPropogation\u001b[0;34m(self, input_data, target_op, learning_rate)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# output_deltas = [0] * len(self.output_l_network.network)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# for i in range(len(self.output_l_network.network)):\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#     output_deltas[i] = self.output_l_network.network[i].cal_error(target_op[i])\u001b[39;00m\n\u001b[1;32m     50\u001b[0m output_deltas \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget_op\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     52\u001b[0m     error_wrt_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_l_network\u001b[38;5;241m.\u001b[39mnetwork[i]\u001b[38;5;241m.\u001b[39merror_wrt_input()\n\u001b[1;32m     53\u001b[0m     output_deltas\u001b[38;5;241m.\u001b[39mappend((target_op[i] \u001b[38;5;241m-\u001b[39m final_output[i]) \u001b[38;5;241m*\u001b[39m error_wrt_input)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.uint8' has no len()"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X_train)):\n",
    "        input_data = X_train[i]\n",
    "        target_output = y_train[i]\n",
    "        \n",
    "        # Perform forward and backward pass\n",
    "        nn.forward_hidden_op(input_data)\n",
    "        nn.backPropogation(input_data, target_output, learning_rate)\n",
    "    \n",
    "    # Calculate total error for the epoch\n",
    "    total_error = nn.calculate_total_error(zip(X_train, y_train))\n",
    "    print(f\"Epoch {epoch+1}, Total Error: {total_error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    input_data = X_test[i]\n",
    "    target_output = y_test[i]\n",
    "    \n",
    "    # Forward pass\n",
    "    output = nn.forward_hidden_op(input_data)\n",
    "    \n",
    "    # Check if the predicted label matches the actual label\n",
    "    if np.argmax(output) == np.argmax(target_output):\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(X_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHIT down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "all_network.__init__() got an unexpected keyword argument 'hidden_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nn \u001b[38;5;241m=\u001b[39m \u001b[43mall_network\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.55\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# dataset = [([0.05, 0.1], [0.01, 0.99])]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# for epoch in range(100):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     nn.backPropogation([0.05, 0.1], [0.01, 0.99])\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     if epoch % 10 == 0:\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#         print(f\"Epoch {epoch}: Error = {nn.calculate_total_error(dataset)}\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: all_network.__init__() got an unexpected keyword argument 'hidden_weights'"
     ]
    }
   ],
   "source": [
    "nn = all_network(2, 2, 2, hidden_weights=[0.15, 0.2, 0.25, 0.3], hidden_bias=0.35, output_weights=[0.4, 0.45, 0.5, 0.55], output_bias=0.6)\n",
    "\n",
    "# dataset = [([0.05, 0.1], [0.01, 0.99])]\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     nn.backPropogation([0.05, 0.1], [0.01, 0.99])\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f\"Epoch {epoch}: Error = {nn.calculate_total_error(dataset)}\")\n",
    "errors = []\n",
    "for i in range(10):\n",
    "    nn.backPropogation([0.05, 0.1], [0.01, 0.99])\n",
    "    error = round(nn.calculate_total_error([([0.05, 0.1], [0.01, 0.99])]), 9)\n",
    "    errors.append(error)\n",
    "    # print(i, round(nn.calculate_total_error([[[0.05, 0.1], [0.01, 0.99]]]), 9))\n",
    "    print(i,error)\n",
    "plt.plot(range(10), errors)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp_lay=784\n",
    "# hidden_lay=64\n",
    "# op_lay=10\n",
    "# hidden_weights=np.random.rand(inp_lay * hidden_lay)\n",
    "# output_weights = np.random.rand(op_lay * hidden_lay)\n",
    "# hid_bias=np.random.rand()\n",
    "# op_bias=np.random.rand()\n",
    "# # print(len(hidden_weights))\n",
    "# # print(len(output_weights))\n",
    "# # print(op_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_lay=784\n",
    "hidden_lay=64\n",
    "op_lay=10\n",
    "hidden_weights=np.random.rand(inp_lay * hidden_lay)*0.1\n",
    "output_weights = np.random.rand(op_lay * hidden_lay)*0.1\n",
    "hid_bias=np.random.rand()\n",
    "op_bias=np.random.rand()\n",
    "mnist_network = all_network(inp_lay, hidden_lay, op_lay,hidden_weights, output_weights, hid_bias, op_bias)\n",
    "input_data = np.random.rand(inp_lay)  # Random input data (e.g., 784 features for one image)\n",
    "target_op = np.random.rand(op_lay)  # Random target output (e.g., 10 classes)\n",
    "\n",
    "# epochs = 5\n",
    "# for epoch in range(epochs):\n",
    "#     mnist_network.backPropogation(input_data, target_op, learning_rate=0.01)\n",
    "#     error = mnist_network.calculate_total_error([(input_data, target_op)])\n",
    "#     print(f\"Total error: {error}\")\n",
    "# epochs = 10\n",
    "# learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a=np.random.rand(inp_lay * hidden_lay)\n",
    "# hidden_weights=np.random.rand(inp_lay * hidden_lay)*0.1\n",
    "# print(a[0],hidden_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = X_train.reshape(784,)\n",
    "# input_data.shape\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_train_flattened = X_train.reshape(-1, 784) / 255.0\n",
    "X_train_flattened.shape\n",
    "# Instantiate the encoder with sparse_output set to False\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the labels into one-hot encoded format\n",
    "y_train_one_hot = encoder.fit_transform(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/0, Total Error: 84.70997609786079\n",
      "Epoch 2/1, Total Error: 41.895059393639904\n",
      "Epoch 3/2, Total Error: 41.914483844124206\n",
      "Epoch 4/3, Total Error: 41.916306646204646\n",
      "Epoch 5/4, Total Error: 41.91549906522271\n",
      "Epoch 6/5, Total Error: 41.91412854858893\n",
      "Epoch 7/6, Total Error: 41.91262695458628\n",
      "Epoch 8/7, Total Error: 41.91109051686448\n",
      "Epoch 9/8, Total Error: 41.90953982282212\n",
      "Epoch 10/9, Total Error: 41.90797763632672\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "errors=[]\n",
    "for e in range(10):\n",
    "    total_error = 0\n",
    "    for i in range(len(X_train_flattened[:100])):\n",
    "        # Print the current image index being trained on\n",
    "        # print(f\"Training on image {i + 1}/{len(X_train_flattened[:1000])}\")\n",
    "        \n",
    "        # Display the current training image\n",
    "        # if i % 100 == 0:  # Display every 100th image to avoid too many outputs\n",
    "        #     plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "        #     plt.title(f\"Training Image: {i + 1}\")\n",
    "        #     plt.show()\n",
    "\n",
    "        # Backpropagation for the current image\n",
    "        mnist_network.backPropogation(X_train_flattened[i], y_train_one_hot[i], 0.1)\n",
    "        total_error += mnist_network.calculate_total_error([(X_train_flattened[i], y_train_one_hot[i])])\n",
    "    errors.append(total_error)\n",
    "    print(f\"Epoch {e + 1}/{e}, Total Error: {total_error}\")\n",
    "plt.plot(range(10), errors)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16aa84ad0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=mnist_network.forward_hidden_op(X_test[2])\n",
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.14562695],\n",
       "       [0.06274676],\n",
       "       [0.06274639],\n",
       "       [0.06274639],\n",
       "       [0.06274639],\n",
       "       [0.06274639],\n",
       "       [0.06274639],\n",
       "       [0.06274639],\n",
       "       [0.06526854],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089],\n",
       "       [0.22385089]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(196)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_digit = np.argmax(aa)\n",
    "predicted_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABUkAAAHqCAYAAAA5289qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAih0lEQVR4nO3de5Dd8/348dcmJNlsCJJIIpUEFa2oS1zGoCLRIISiyRYtEbeEutQQVZcGVUqCmCG0FIN1ixbFoG5VldLUJagacU3cMuKakrhsPr8/8st+rSTNnmQ5J+f1eMzsjH3nfHbf5zOvxNnnnvM5NUVRFAEAAAAAkFSbcm8AAAAAAKCcRFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgtZIi6VVXXRU1NTXxr3/96+vaT0W45JJLYsSIEdG7d++oqamJAw88sNxbWiFlmJeZM2fG6aefHltttVWsvvrq0bVr19hhhx3ivvvuK/fWVjgZ5mXu3Llx8MEHx0YbbRSdO3eOTp06xSabbBIXXnhhfP755+Xe3golw7x81d///veoqamJmpqamD17drm3s0LJMi8L5+OrH7/97W/LvbUVSpZ5iYiYNWtWjB49Onr16hUdOnSIvn37xsEHH1zuba1QMszLwvu4pI+GhoZyb3GFkWFeIiI+/PDDOOGEE2L99deP2tra6NOnTxx88MExY8aMcm9thZJlXmbNmhWjRo2KNddcM2pra2PAgAExefLkcm+romWZjVLa3AcffBCHHXZYdOvWLerq6mLQoEHxxBNPlPw9V1qO/Vatc845J+bMmRNbbbVVvPXWW+XeDhXstttui3POOSf23HPPGDlyZHzxxRdx9dVXx5AhQ+KKK66IUaNGlXuLVJC5c+fGv//979h1112jb9++0aZNm5gyZUoce+yx8dhjj8V1111X7i1SoebPnx9HHXVU1NXVxccff1zu7VDBhgwZEgcccECztc0226xMu6GSzZw5M7bddtuIiBgzZkz06tUr3nzzzfjnP/9Z5p1Rabbffvu45pprFlm/4IILYtq0abHjjjuWYVdUqvnz58eQIUPiueeeiyOOOCL69esXL774YkyaNCnuueee+M9//hOrrLJKubdJhfjoo49iu+22i1mzZsUxxxwTPXr0iJtuuinq6+ujoaEh9ttvv3JvkTJqaZubP39+7LbbbjFt2rQYO3ZsdO3aNSZNmhQ77LBDPP7447H++uu3+HuKpIvx0EMPNZXqTp06lXs7VLBBgwbFjBkzomvXrk1rY8aMiU033TR+9atfiaQ0s8Yaa8Sjjz7abG3MmDHRuXPnuOiii+L888+PHj16lGl3VLLf//73MXPmzDjkkEPiwgsvLPd2qGD9+vWLn/70p+XeBiuA0aNHx0orrRRTp06NLl26lHs7VLB111031l133WZrc+fOjSOOOCIGDx7ssQvNPProozF16tS46KKL4mc/+1nT+gYbbBAHHXRQ3HfffbHXXnuVcYdUkt/97nfx4osvxv333x+DBw+OiIjDDz88tt566zjuuONi+PDh0a5duzLvknJpaZu7+eabY8qUKTF58uQYPnx4RETU19dHv379Yty4cSU9GWm5r0l64IEHRqdOnWLGjBkxbNiw6NSpU/Tq1SsuvvjiiIh45plnYvDgwVFXVxd9+vRZZHPvvfdeHH/88fG9730vOnXqFKuuumoMHTo0pk2btsj3eu2112KPPfaIurq6WHPNNePYY4+Ne+65J2pqauKvf/1rs9s+9thjscsuu0Tnzp2jY8eOMXDgwHjkkUdadJ/69OkTNTU1y3ZC+J+qbV769+/fLJBGRLRv3z523XXXeP3112POnDklniG+rNrmZUn69u0bEQteIsCyq9Z5ee+99+KUU06JM844I1ZbbbWSzwuLV63zErEgXsybN6+0E8L/VG3z8vzzz8ddd90VY8eOjS5dusS8efNc9qUVVdu8LM7tt98ec+bMiZ/85CfLdDz/p9rm5aOPPoqIiO7duzdb79mzZ0RE1NbWtvjcsKhqm5eHH344unXr1hRIIyLatGkT9fX18fbbb8dDDz20DGcpp2qbjYiWt7mbb745unfvHnvvvXfTWrdu3aK+vj5uu+22+PTTT1v0/SJa6Y2bGhsbY+jQobH22mvHueeeG3379o0jjzwyrrrqqthll11iiy22iHPOOSdWWWWVOOCAA+KVV15pOvbll1+OW2+9NYYNGxbnn39+jB07Np555pkYOHBgvPnmm023+/jjj2Pw4MFx3333xdFHHx0nn3xyTJkyJX7xi18ssp8HHnggtt9++/joo49i3LhxcdZZZ8UHH3wQgwcP9hKiCpBhXt5+++3o2LFjdOzYcZmO5/9U47x89tlnMXv27Jg5c2bccsstMWHChOjTp098+9vfXv4Tllw1zsupp54aPXr0iNGjRy//CaKZapyXq666Kurq6qK2tjY23HBDl/FoRdU0Lwuvnd69e/fYcccdo7a2Nmpra2Po0KHx6quvts4JS66a5mVxGhoaora2ttkPpCy7apqXLbbYIurq6uLUU0+NBx54IN5444146KGH4oQTTogtt9wyfvCDH7TeiUuqmubl008/XWw4X/hz9OOPP76spymlapqNUjz55JMxYMCAaNOmeeLcaqut4pNPPokXXnih5V+sKMGVV15ZREQxderUprWRI0cWEVGcddZZTWvvv/9+UVtbW9TU1BQ33HBD0/rzzz9fREQxbty4prV58+YVjY2Nzb7PK6+8UrRv374444wzmtbOO++8IiKKW2+9tWlt7ty5xXe+850iIooHH3ywKIqimD9/frH++usXO++8czF//vym237yySfFOuusUwwZMqSUu1zU1dUVI0eOLOkYFsg4L0VRFNOnTy86dOhQ7L///iUfm1mmebn++uuLiGj62GKLLYqnn366RceyQJZ5mTZtWtG2bdvinnvuKYqiKMaNG1dERPHOO+8s9Vj+T5Z52WabbYqJEycWt912W3HJJZcUG220URERxaRJk5Z+kmiSYV6OPvroIiKKLl26FLvssktx4403FuPHjy86depUrLfeesXHH3/cspNFinn5qnfffbdo165dUV9fX9Jx5JmXO+64o+jZs2ezx7s777xzMWfOnKWfJJpkmJejjjqqaNOmTfHqq682W99nn32KiCiOPPLI/3l8Vhlm46v+V5urq6srDjrooEXW77zzziIiirvvvrvF36dVnkkaEXHIIYc0/fdqq60WG2ywQdTV1UV9fX3T+gYbbBCrrbZavPzyy01r7du3b6q9jY2N8e6770anTp1igw02aPZOVHfffXf06tUr9thjj6a1Dh06xKGHHtpsH0899VRMnz499ttvv3j33Xdj9uzZMXv27Pj4449jxx13jL/97W8xf/781rrbLKNqnZdPPvkkRowYEbW1td5NuBVV27wMGjQo7r333pg8eXKMGTMmVl55ZW/G04qqaV6OPvroGDp0aOy0007LdjJYqmqal0ceeSSOOeaY2GOPPWLMmDHx+OOPx0YbbRQnnXRSzJ07d9lOEM1Uy7z897//jYiIHj16xJ133hn19fVx/PHHx2WXXRYvvfSSZyC3kmqZl6+6+eab47PPPvNS+1ZWTfPSrVu32GyzzeI3v/lN3HrrrXHaaafFww8/7P0aWlG1zMshhxwSbdu2jfr6+pgyZUq89NJLcfbZZ8ctt9wSEeHxyzKoltkoxdy5c6N9+/aLrHfo0KHpz1uqVd64qUOHDtGtW7dma507d45vfetbi1w/oHPnzvH+++83fT5//vy48MILY9KkSfHKK69EY2Nj0599+SLyr732Wqy33nqLfL2vvjx1+vTpERExcuTIJe73ww8/jNVXX72F947WVq3z0tjYGPvss08899xzcdddd8Vaa6211GNYumqcl+7duzddp2n48OFx1llnxZAhQ2L69One/GA5VdO83HjjjTFlypR49tlnl3g8y6ea5mVx2rVrF0ceeWRTMN1uu+1afCyLqqZ5WfjSxvr6+mYvTRsxYkTsv//+MWXKlGY/ZFG6apqXr2poaIg11lgjhg4d2qLbs3TVNC8vv/xyDBo0KK6++ur40Y9+FBERP/zhD6Nv375x4IEHxl133WV2llM1zcvGG28c1113XYwZMya23XbbiFjwC7yJEyfG4Ycf7o20S1RNs1GK2traxV53dOE1+ku5FnKrRNK2bduWtF4URdN/n3XWWXHqqafGQQcdFL/+9a9jjTXWiDZt2sTPf/7zZarKC48ZP358bLrppou9jb9o5VWt83LooYfGHXfcEQ0NDc0uPM3yqdZ5+bLhw4fHySefHLfddpvrTi6napqXsWPHxogRI6Jdu3ZN1whc+OZeM2fOjM8++8wvY5ZTNc3Lkqy99toRseBi/CyfapqXhf92fPWNVdq2bRtdunRp9kMTy6aa5uXLZsyYEQ8//HAcdthhsfLKK5e8Fxavmublqquuinnz5sWwYcOarS981tkjjzwiki6napqXiAU/C+2xxx4xbdq0aGxsjAEDBjS9+U+/fv1K3lNm1TYbLdWzZ8946623FllfuFbKz0ytEkmXx8033xyDBg2KP/zhD83WP/jgg2bvGt6nT5947rnnoiiKZsX6xRdfbHbceuutFxERq666qotCV6FKnZexY8fGlVdeGRMnTox99913mb8OratS5+WrFj79/8MPP2y1r0npKm1eZs6cGdddd91iX/Y6YMCA2GSTTeKpp54q+evSOiptXpZk4cuovvqsAr5ZlTYvm2++eUREvPHGG83WF76xoHkpr0qbly+7/vrroygKL7WvIJU2L7NmzYqiKJo9Cy0i4vPPP4+IiC+++KLkr0nrqbR5Wahdu3ax5ZZbNn2+8A0GNZ1vTqXORktsuumm8fDDD8f8+fObvULmsccei44dO5YU21vtmqTLqm3bts3qdUTE5MmTF3nQtvPOO8cbb7wRf/7zn5vW5s2bF5dddlmz222++eax3nrrxYQJE5qut/Rl77zzTivunm9aJc7L+PHjY8KECXHSSSfFMcccU8rd4WtWafMye/bsRfYTEXH55ZdHxIJ3A6V8Km1ebrnllkU+fvzjH0dExNVXXx0XXHBBSfeP1lVp87K4P58zZ05MnDgxunbt2hTFKI9Km5cddtgh1lxzzWhoaGh6KVrEgmeANTY2xpAhQ1p832h9lTYvX3bddddF7969Xb6jglTavPTr1y+Kooibbrqp2fr1118fERGbbbbZ0u8UX5tKm5fFmT59elx66aUxbNgwzyT9Bq0Is7Ekw4cPj1mzZsWf/vSnprXZs2fH5MmTY/fdd1/s9UqXpOzPJB02bFicccYZMWrUqNhmm23imWeeiYaGhlh33XWb3W706NFx0UUXxb777hvHHHNM9OzZMxoaGpouxLqwYLdp0yYuv/zyGDp0aPTv3z9GjRoVvXr1ijfeeCMefPDBWHXVVeP222//n3u6/fbbY9q0aRGx4DdeTz/9dJx55pkRseBlAhtvvHFrnwZaqNLm5ZZbbokTTjgh1l9//fjud78b1157bbM/HzJkyCIvZeObU2nzcu2118all14ae+65Z6y77roxZ86cuOeee+Lee++N3Xff3WUayqzS5mXPPfdcZG3hM0eHDh3a7De6fPMqbV4uvvjiuPXWW2P33XeP3r17x1tvvRVXXHFFzJgxI6655ppo167d13cyWKpKm5f27dvH+PHjY+TIkbH99tvH/vvvHzNmzIgLL7wwvv/978fee+/99Z0MlqrS5mWhZ599Np5++uk48cQTF7kWHeVTafNy4IEHxoQJE2L06NHx5JNPRv/+/eOJJ56Iyy+/PPr37x977bXX13cyWKpKm5eIiA033DBGjBgRvXv3jldeeSUuueSSWGONNeLSSy/9ek4Ci1WJs9HSNjd8+PDYeuutY9SoUfHcc89F165dY9KkSdHY2Binn356aSdiyW98v6grr7yyiIhi6tSpTWsjR44s6urqFrntwIEDi/79+y+y3qdPn2K33XZr+nzevHnFcccdV/Ts2bOora0ttt122+If//hHMXDgwGLgwIHNjn355ZeL3XbbraitrS26detWHHfcccUf//jHIiKKRx99tNltn3zyyWLvvfcuunTpUrRv377o06dPUV9fX9x///1LvZ8jR44sImKxH1deeeVSj2eBDPMybty4Jc5KRBQPPvhgC84URZFjXqZOnVqMGDGi6N27d9G+ffuirq6uGDBgQHH++ecXn3/+eUtOE/9fhnlZnIX/5rzzzjslH5tZhnn5y1/+UgwZMqTo0aNHsfLKKxerrbZasdNOOy3TnGWXYV4Wuv7664tNNtmkaN++fdG9e/fiyCOPLD766KMWHcsCmeblxBNPLCKiePrpp1t0exaVZV5ef/314qCDDirWWWedol27dkXPnj2LQw891OOXEmWZl3322adYe+21i3bt2hVrrbVWMWbMmGLWrFlLPS6zLLNRSpt77733ioMPPrjo0qVL0bFjx2LgwIHNzk9L1RTFYl77uQKZOHFiHHvssfH6669Hr169yr0dKpx5oRTmhVKYF0phXiiFeaEU5oVSmBdKYV5YkmqZjRUqks6dOzdqa2ubPp83b15sttlm0djYGC+88EIZd0YlMi+UwrxQCvNCKcwLpTAvlMK8UArzQinMC0tSzbNR9muSlmLvvfeO3r17x6abbhoffvhhXHvttfH8889HQ0NDubdGBTIvlMK8UArzQinMC6UwL5TCvFAK80IpzAtLUs2zsUJF0p133jkuv/zyaGhoiMbGxthwww3jhhtuaHq3X/gy80IpzAulMC+UwrxQCvNCKcwLpTAvlMK8sCTVPBsr1MvtAQAAAABaW5tybwAAAAAAoJxEUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABIbaVyb+CrJkyYsFzHH3/88a20E1YEZ5999nId/8tf/rKVdsKK4LTTTivr8axYzjzzzOU6/pRTTmmlnbAiMC+UYuzYsct1/Pjx41tpJ6wIzj333OU6/oQTTmilnbAiOO+885br+OOOO66VdsKKQH+hFBke73omKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqdUURVGUexNfVlNTs1zHV9jd4WtmXiiFeaEU5oVSmBdKYV4ohXmhFOaFUpgXSpFhXjyTFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1ERSAAAAACA1kRQAAAAASE0kBQAAAABSE0kBAAAAgNREUgAAAAAgNZEUAAAAAEhNJAUAAAAAUhNJAQAAAIDURFIAAAAAIDWRFAAAAABITSQFAAAAAFITSQEAAACA1FYq9wa+qm3btuXeAisQ80Ip2rTxeyFazr8vlGKllSruIRUVzLxQCvNCKTx+oRR+PqIUGf5/5G8EAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACp1RRFUZR7EwAAAAAA5eKZpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBqIikAAAAAkJpICgAAAACkJpICAAAAAKmJpAAAAABAaiIpAAAAAJCaSAoAAAAApCaSAgAAAACpiaQAAAAAQGoiKQAAAACQmkgKAAAAAKQmkgIAAAAAqYmkAAAAAEBq/w86VCg+J/8BpQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# num_images = len(aa)\n",
    "# fig, axes = plt.subplots(1, num_images, figsize=(15, 5))  # Adjust figsize for better visibility\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(aa[i], cmap='gray')  # Use 'gray' if these are grayscale images\n",
    "#     ax.axis('off')  # Hide axes for better visualization\n",
    "#     ax.set_title(f\"Image {i+1}\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(196)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(aa)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, bias):\n",
    "        self.bias = bias\n",
    "        self.weights = []\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"Numerically stable sigmoid.\"\"\"\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -100, 100)))\n",
    "\n",
    "    def sum_input_to_hidden(self):\n",
    "        \"\"\"Calculate weighted sum + bias.\"\"\"\n",
    "        weighted_sum = sum(self.input[i] * self.weights[i] for i in range(len(self.input)))\n",
    "        return weighted_sum + self.bias\n",
    "\n",
    "    def cost(self, input_data):\n",
    "        \"\"\"Forward propagation: calculate output.\"\"\"\n",
    "        self.input = input_data\n",
    "        self.output = self.sigmoid(self.sum_input_to_hidden())\n",
    "        return self.output\n",
    "\n",
    "    def error_wrt_output(self, target_op):\n",
    "        \"\"\"Error derivative with respect to output.\"\"\"\n",
    "        return -(target_op - self.output)\n",
    "\n",
    "    def error_wrt_input(self):\n",
    "        \"\"\"Derivative of activation function.\"\"\"\n",
    "        return self.output * (1 - self.output)\n",
    "\n",
    "    def total_error(self, target_op):\n",
    "        \"\"\"Total error for a neuron.\"\"\"\n",
    "        return self.error_wrt_input() * self.error_wrt_output(target_op)\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, hidden_layer, bias):\n",
    "        self.network = []\n",
    "        self.bias = bias if bias is not None else np.random.rand()\n",
    "        for _ in range(hidden_layer):\n",
    "            self.network.append(Neuron(self.bias))\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"Forward propagation for the network.\"\"\"\n",
    "        outputs = [neuron.cost(input_data) for neuron in self.network]\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class AllNetwork:\n",
    "    def __init__(self, n_input_layer, n_hidden_layer, n_output_layer, hidden_weights, output_weights, hidden_bias, output_bias):\n",
    "        self.hidden_l_network = Network(n_hidden_layer, hidden_bias)\n",
    "        self.output_l_network = Network(n_output_layer, output_bias)\n",
    "        self.n_input_layer = n_input_layer\n",
    "        self.add_weights(self.hidden_l_network, hidden_weights, n_input_layer)\n",
    "        self.add_weights(self.output_l_network, output_weights, n_hidden_layer)\n",
    "\n",
    "    def add_weights(self, layer, weights, num_inputs):\n",
    "        \"\"\"Initialize weights for a network layer.\"\"\"\n",
    "        count = 0\n",
    "        for neuron in layer.network:\n",
    "            neuron.weights = weights[count:count + num_inputs]\n",
    "            count += num_inputs\n",
    "\n",
    "    def forward_hidden_op(self, input_data):\n",
    "        \"\"\"Forward propagation through hidden and output layers.\"\"\"\n",
    "        hidden_output = self.hidden_l_network.forward(input_data)\n",
    "        output = self.output_l_network.forward(hidden_output)\n",
    "        return output\n",
    "\n",
    "    def back_propagation(self, input_data, target_op, learning_rate=0.5):\n",
    "        \"\"\"Backpropagation to update weights and biases.\"\"\"\n",
    "        # Forward pass\n",
    "        hidden_output = self.hidden_l_network.forward(input_data)\n",
    "        final_output = self.output_l_network.forward(hidden_output)\n",
    "\n",
    "        # Output layer deltas\n",
    "        output_deltas = []\n",
    "        for i in range(len(target_op)):\n",
    "            error_wrt_input = self.output_l_network.network[i].error_wrt_input()\n",
    "            output_deltas.append((target_op[i] - final_output[i]) * error_wrt_input)\n",
    "\n",
    "        # Hidden layer deltas\n",
    "        hidden_deltas = []\n",
    "        for i in range(len(self.hidden_l_network.network)):\n",
    "            weighted_sum = sum(\n",
    "                output_deltas[j] * self.output_l_network.network[j].weights[i]\n",
    "                for j in range(len(self.output_l_network.network))\n",
    "            )\n",
    "            hidden_deltas.append(weighted_sum * self.hidden_l_network.network[i].error_wrt_input())\n",
    "\n",
    "        # Update output layer weights and biases\n",
    "        for i, neuron in enumerate(self.output_l_network.network):\n",
    "            for j in range(len(neuron.weights)):\n",
    "                neuron.weights[j] += learning_rate * output_deltas[i] * hidden_output[j]\n",
    "            neuron.bias += learning_rate * output_deltas[i]\n",
    "\n",
    "        # Update hidden layer weights and biases\n",
    "        for i, neuron in enumerate(self.hidden_l_network.network):\n",
    "            for j in range(len(neuron.weights)):\n",
    "                neuron.weights[j] += learning_rate * hidden_deltas[i] * input_data[j]\n",
    "            neuron.bias += learning_rate * hidden_deltas[i]\n",
    "\n",
    "    def calculate_total_error(self, dataset):\n",
    "        \"\"\"Compute total error for the dataset.\"\"\"\n",
    "        total_error = 0\n",
    "        for input_data, target_op in dataset:\n",
    "            outputs = self.forward_hidden_op(input_data)\n",
    "            total_error += sum(0.5 * (target_op[i] - outputs[i]) ** 2 for i in range(len(target_op)))\n",
    "        return total_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Total Error: 0.374310\n",
      "Epoch 100, Total Error: 0.003950\n",
      "Epoch 200, Total Error: 0.001612\n",
      "Epoch 300, Total Error: 0.000944\n",
      "Epoch 400, Total Error: 0.000639\n",
      "Epoch 500, Total Error: 0.000469\n",
      "Epoch 600, Total Error: 0.000362\n",
      "Epoch 700, Total Error: 0.000290\n",
      "Epoch 800, Total Error: 0.000238\n",
      "Epoch 900, Total Error: 0.000199\n",
      "Predicted Output: [np.float64(0.02321167966823035), np.float64(0.9771681221210514)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize neural network parameters\n",
    "n_input = 3\n",
    "n_hidden = 4\n",
    "n_output = 2\n",
    "hidden_weights = [0.15, 0.2, 0.35, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65]\n",
    "output_weights = [0.45, 0.5, 0.55, 0.6, 0.4, 0.35, 0.3, 0.25]\n",
    "hidden_bias = 0.35\n",
    "output_bias = 0.6\n",
    "\n",
    "# Create a network\n",
    "network = AllNetwork(n_input, n_hidden, n_output, hidden_weights, output_weights, hidden_bias, output_bias)\n",
    "\n",
    "# Sample dataset\n",
    "dataset = [([0.05, 0.1, 0.2], [0.01, 0.99])]\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(1000):\n",
    "    for input_data, target_op in dataset:\n",
    "        network.back_propagation(input_data, target_op, learning_rate=0.5)\n",
    "    if epoch % 100 == 0:\n",
    "        error = network.calculate_total_error(dataset)\n",
    "        print(f\"Epoch {epoch}, Total Error: {error:.6f}\")\n",
    "\n",
    "# Predict using the trained network\n",
    "sample_input = [0.05, 0.1, 0.2]\n",
    "output = network.forward_hidden_op(sample_input)\n",
    "print(\"Predicted Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aa=mnist_network.forward_hidden_op(X_test[2])\n",
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m     batch_y \u001b[38;5;241m=\u001b[39m y_train_one_hot[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_data, target_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_x, batch_y):\n\u001b[0;32m--> 139\u001b[0m         \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mback_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Calculate error for this epoch\u001b[39;00m\n\u001b[1;32m    142\u001b[0m total_error \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mcalculate_total_error(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(x_train[:\u001b[38;5;241m100\u001b[39m], y_train_one_hot[:\u001b[38;5;241m100\u001b[39m])))\n",
      "Cell \u001b[0;32mIn[87], line 85\u001b[0m, in \u001b[0;36mAllNetwork.back_propagation\u001b[0;34m(self, input_data, target_op, learning_rate)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer\u001b[38;5;241m.\u001b[39mnetwork):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(neuron\u001b[38;5;241m.\u001b[39mweights)):\n\u001b[0;32m---> 85\u001b[0m         neuron\u001b[38;5;241m.\u001b[39mweights[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m hidden_deltas[i] \u001b[38;5;241m*\u001b[39m input_data[j]\n\u001b[1;32m     86\u001b[0m     neuron\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m hidden_deltas[i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, bias):\n",
    "        self.bias = bias\n",
    "        self.weights = []\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"Numerically stable sigmoid.\"\"\"\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -100, 100)))\n",
    "\n",
    "    def sum_input_to_hidden(self):\n",
    "        \"\"\"Calculate weighted sum + bias.\"\"\"\n",
    "        return sum(self.input[i] * self.weights[i] for i in range(len(self.input))) + self.bias\n",
    "\n",
    "    def cost(self, input_data):\n",
    "        \"\"\"Forward propagation: calculate output.\"\"\"\n",
    "        self.input = input_data\n",
    "        self.output = self.sigmoid(self.sum_input_to_hidden())\n",
    "        return self.output\n",
    "\n",
    "    def error_wrt_output(self, target_op):\n",
    "        \"\"\"Error derivative with respect to output.\"\"\"\n",
    "        return -(target_op - self.output)\n",
    "\n",
    "    def error_wrt_input(self):\n",
    "        \"\"\"Derivative of activation function.\"\"\"\n",
    "        return self.output * (1 - self.output)\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, num_neurons, bias):\n",
    "        self.network = [Neuron(bias) for _ in range(num_neurons)]\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"Forward propagation for the network.\"\"\"\n",
    "        return [neuron.cost(input_data) for neuron in self.network]\n",
    "\n",
    "\n",
    "class AllNetwork:\n",
    "    def __init__(self, n_input, n_hidden, n_output, hidden_bias, output_bias):\n",
    "        self.hidden_layer = Network(n_hidden, hidden_bias)\n",
    "        self.output_layer = Network(n_output, output_bias)\n",
    "        self.initialize_weights(self.hidden_layer, n_input)\n",
    "        self.initialize_weights(self.output_layer, n_hidden)\n",
    "\n",
    "    def initialize_weights(self, layer, num_inputs):\n",
    "        \"\"\"Randomly initialize weights for neurons.\"\"\"\n",
    "        for neuron in layer.network:\n",
    "            neuron.weights = np.random.uniform(-0.5, 0.5, num_inputs).tolist()\n",
    "\n",
    "    def forward_hidden_op(self, input_data):\n",
    "        \"\"\"Forward propagation through the network.\"\"\"\n",
    "        hidden_output = self.hidden_layer.forward(input_data)\n",
    "        output = self.output_layer.forward(hidden_output)\n",
    "        return hidden_output, output\n",
    "\n",
    "    def back_propagation(self, input_data, target_op, learning_rate=0.01):\n",
    "        \"\"\"Backpropagation to update weights and biases.\"\"\"\n",
    "        # Forward pass\n",
    "        hidden_output, final_output = self.forward_hidden_op(input_data)\n",
    "\n",
    "        # Calculate output layer deltas\n",
    "        output_deltas = [(target_op[i] - final_output[i]) * self.output_layer.network[i].error_wrt_input()\n",
    "                         for i in range(len(target_op))]\n",
    "\n",
    "        # Calculate hidden layer deltas\n",
    "        hidden_deltas = []\n",
    "        for i in range(len(self.hidden_layer.network)):\n",
    "            weighted_sum = sum(output_deltas[j] * self.output_layer.network[j].weights[i]\n",
    "                               for j in range(len(self.output_layer.network)))\n",
    "            hidden_deltas.append(weighted_sum * self.hidden_layer.network[i].error_wrt_input())\n",
    "\n",
    "        # Update output layer weights and biases\n",
    "        for i, neuron in enumerate(self.output_layer.network):\n",
    "            for j in range(len(neuron.weights)):\n",
    "                neuron.weights[j] += learning_rate * output_deltas[i] * hidden_output[j]\n",
    "            neuron.bias += learning_rate * output_deltas[i]\n",
    "\n",
    "        # Update hidden layer weights and biases\n",
    "        for i, neuron in enumerate(self.hidden_layer.network):\n",
    "            for j in range(len(neuron.weights)):\n",
    "                neuron.weights[j] += learning_rate * hidden_deltas[i] * input_data[j]\n",
    "            neuron.bias += learning_rate * hidden_deltas[i]\n",
    "\n",
    "    def calculate_total_error(self, dataset):\n",
    "        \"\"\"Compute total error for the dataset.\"\"\"\n",
    "        total_error = 0\n",
    "        for input_data, target_op in dataset:\n",
    "            _, outputs = self.forward_hidden_op(input_data)\n",
    "            total_error += sum(0.5 * (target_op[i] - outputs[i]) ** 2 for i in range(len(target_op)))\n",
    "        return total_error\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        \"\"\"Make predictions based on the forward pass.\"\"\"\n",
    "        _, outputs = self.forward_hidden_op(input_data)\n",
    "        return np.argmax(outputs)\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        \"\"\"Evaluate the accuracy of the network.\"\"\"\n",
    "        correct = 0\n",
    "        for input_data, label in zip(x_test, y_test):\n",
    "            prediction = self.predict(input_data)\n",
    "            if prediction == label:\n",
    "                correct += 1\n",
    "        return correct / len(x_test)\n",
    "\n",
    "\n",
    "# Load MNIST Dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Initialize network\n",
    "n_input = 784\n",
    "n_hidden = 128\n",
    "n_output = 10\n",
    "hidden_bias = 0.35\n",
    "output_bias = 0.6\n",
    "\n",
    "network = AllNetwork(n_input, n_hidden, n_output, hidden_bias, output_bias)\n",
    "\n",
    "# Train the network\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        batch_x = x_train[i:i + batch_size]\n",
    "        batch_y = y_train_one_hot[i:i + batch_size]\n",
    "        for input_data, target_op in zip(batch_x, batch_y):\n",
    "            network.back_propagation(input_data, target_op, learning_rate)\n",
    "\n",
    "    # Calculate error for this epoch\n",
    "    total_error = network.calculate_total_error(list(zip(x_train[:100], y_train_one_hot[:100])))\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Total Error: {total_error:.4f}\")\n",
    "\n",
    "# Evaluate on test data\n",
    "accuracy = network.evaluate(x_test[:100], y_test[:100])\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
